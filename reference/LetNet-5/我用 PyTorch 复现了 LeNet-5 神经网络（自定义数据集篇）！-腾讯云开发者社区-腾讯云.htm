<!DOCTYPE html><html lang="zh" munual-autotracker-init="" qct-uid="" qct-pv-id="mLMi6dwh83lCNxzIoDO9H" qct-ip="182.113.29.210"><head><meta charSet="UTF-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="format-detection" content="telephone=no"/><title>我用 PyTorch 复现了 LeNet-5 神经网络（自定义数据集篇）！-腾讯云开发者社区-腾讯云</title><meta name="subject" content="通用技术-人工智能技术-pytorch,通用技术-人工智能技术-神经网络,通用技术-人工智能技术-卷积神经网络,平台服务-空类-腾讯云测试服务,通用技术-开发技术-github"/><meta name="subjectTime" content="2022-01-10 14:35:28"/><meta name="articleSource" content="B"/><meta name="magicSource" content="N"/><meta name="authorType" content="Z"/><meta name="productSlug" content="crg"/><meta name="keywords" content="pytorch,神经网络,卷积神经网络,腾讯云测试服务,github"/><meta name="description" content="我用 PyTorch 复现了 LeNet-5 神经网络（MNIST 手写数据集篇）！"/><meta property="og:title" content="我用 PyTorch 复现了 LeNet-5 神经网络（自定义数据集篇）！-腾讯云开发者社区-腾讯云"/><meta property="og:description" content="我用 PyTorch 复现了 LeNet-5 神经网络（MNIST 手写数据集篇）！"/><meta property="og:image" content="https://cloudcache.tencentcs.com/open_proj/proj_qcloud_v2/gateway/shareicons/cloud.png"/><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1, viewport-fit=cover"/><link rel="dns-prefetch" href="//qccommunity.qcloudimg.com"/><link rel="dns-prefetch" href="//ask.qcloudimg.com"/><link rel="dns-prefetch" href="//cloudcache.tencentcs.com"/><link rel="canonical" href="https://cloud.tencent.com/developer/article/1931716"/><meta name="next-head-count" content="20"/><link rel="stylesheet" href="https://imgcache.qq.com/open_proj/proj_qcloud_v2/gateway/portal/css/base.css"/><link rel="stylesheet" href="https://cloudcache.tencentcs.cn/qcloud/ui/cloud-community/build/base/base-202407291447.css"/><style type="text/css">
        .rno-markdown p * {
          white-space: pre-wrap;
          word-break: break-all;
        }
      </style><link rel="stylesheet" href="https://cloudcache.tencentcs.cn/qcloud/ui/cloud-community/build/Article/Article-202407291450.css"/><link rel="stylesheet" href="https://cloudcache.tencent-cloud.cn/qcloud/draft-master/dist/draft-master-v2.0.111.d4s2ddo9sb.css"/><link rel="stylesheet" href="https://qccommunity.qcloudimg.com/tc_player/release/tcplayer.min.css"/><script src="https://tam.cdn-go.cn/aegis-sdk/latest/aegis.min.js"></script><script>
              if (Aegis) {
                new Aegis({
                  id: 'dWlmyFvjDnalkbZO8q',
                  env: 'production',
                  onError: true,
                  pagePerformance: true,
                  reportAssetSpeed: true,
                  api: {
                    reportRequest: true,
                    resHeaders: ['x-req-id'],
                  },
                  reportApiSpeed: true,
                  beforeRequest: function (data) {
                    // load js failed
                    if (data.logType === 'log') {
                      if (data.logs.level === '32' && data.logs.msg.indexOf('google') > -1) return false;
                    }
                    var ignoreKeys = [
                      'Script error',
                      'chrome-extension',
                      'qq.com',
                      'queryWeappQrcodeStatus',
                      'login/ajax/info',
                      'woa.com',
                      'trafficCollect.php',
                      'google',
                      'dscache',
                      'act-api',
                      'set_qc_cookie',
                      'opc.cloud.tencent.com',
                      'uc_gre_ad_buss',
                      'eb.xcj.pub',
                      'UCShellJava',
                      '/developer/labs/quick/loader',
                      'edgeImmersiveReaderDOM',
                      'sendBeacon',
                      'error-decoder.html'
                    ];
                    var alarmMsg = [data.logs.url, data.logs.msg].join('|');
                    for (var i = 0; i < ignoreKeys.length; i++) {
                      if (alarmMsg.indexOf(ignoreKeys[i]) != -1) return false;
                    }
                    if (/bot|wechatdevtools|spider/i.test(navigator.userAgent)) {
                      return false;
                    }
                    if (location.hostname.indexOf('cloud.tencent.') === -1) {
                      return false;
                    }
                  },
                });
              }
    </script><link rel="preload" href="https://qccommunity.qcloudimg.com/community/_next/static/css/39f449b3fd0e7d7d.css" as="style"/><link rel="stylesheet" href="https://qccommunity.qcloudimg.com/community/_next/static/css/39f449b3fd0e7d7d.css" data-n-g=""/><link rel="preload" href="https://qccommunity.qcloudimg.com/community/_next/static/css/53e572c46176f71a.css" as="style"/><link rel="stylesheet" href="https://qccommunity.qcloudimg.com/community/_next/static/css/53e572c46176f71a.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/webpack-e8c5bfd090283143.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/framework-bae252e255276064.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/main-7da41932fd580784.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/pages/_app-0272fcf27a785156.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/7247-b29db76fc7394892.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/9516-ed06f8b5b6d7461c.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/3560-1b350c07259e815f.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/3127-2d265d7011e04a8f.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/6249-8c67f10599327a0e.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/9835-7f3adb837c602e11.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/503-62afac4ccb82a529.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/1925-36f73c55c4d2f952.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/3887-0dcd5d3152f3302c.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/2418-1e98ff5353c4371a.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/6415-784cef7adb6b1a60.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/404-c2b9b4dabf86f7f8.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/1870-ec71c5134fdbdc19.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/9752-3ade169c6f43aa08.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/6517-328a4a00de77be8b.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/5668-131505b8b5c716ba.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/1323-5a3b99daaaac578e.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/6387-05874ad0d8879f81.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/6315-a18fbcf2effa9c20.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/4525-d56aaefefd3ad282.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/chunks/pages/article/%5BarticleId%5D-de34acf08773b79a.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/TBn4s1UqVQWVFb5OkG95R/_buildManifest.js" defer=""></script><script src="https://qccommunity.qcloudimg.com/community/_next/static/TBn4s1UqVQWVFb5OkG95R/_ssgManifest.js" defer=""></script></head><body class=""><div id="__next"><script src="https://dscache.tencent-cloud.cn/ecache/qcstat/qcloud/qcloudStatApi.js"></script><script src="https://qccommunity.qcloudimg.com/common/exposure-plugin-4.1.15.min.js"></script><script src="https://qccommunity.qcloudimg.com/community-track/qcloud-community-track.min.js"></script><div class="cdc-responsive-layout" aegis-first-screen-timing="true" qct-area="文章详情页"><div class="cdc-article-page cdc-global"><div class="cdc-sticky-header mod-sticky-header is-hidden" style="left:0"><div class="cdc-sticky-header__inner"><div class="cdc-sticky-header__main"><div class="mod-sticky-header__main"><div class="mod-sticky-header__author"><span class="cdc-avatar circle"><a class="cdc-avatar__inner" style="background-image:url(https://ask.qcloudimg.com/avatar/1148605/0awbobj21j.jpg)" href="/developer/user/1148605" target="_blank"></a></span><div class="author-info"><a class="author-info__name" href="/developer/user/1148605" target="_blank"><span class="name-text">红色石头</span></a></div></div><div class="mod-sticky-header__split"></div><div class="mod-sticky-header__title"><div class="mod-sticky-header__title-content"><h2 class="title-text">我用 PyTorch 复现了 LeNet-5 神经网络（自定义数据集篇）！</h2></div></div></div></div><div class="cdc-sticky-header__extra"><div class="mod-sticky-header__operates"><button class="cdc-btn mod-sticky-header__operate btn-focus cdc-btn--primary"><i class="add-icon"></i><span>关注作者</span></button></div></div></div></div><div class="cdc-m-guider-banner"><div class="cdc-m-guider-banner__guide-mvp is-detail-page"><div class="cdc-m-guider-banner__guide-mvp-text">前往小程序，Get<em>更优</em>阅读体验！</div><div class="cdc-m-guider-banner__guide-mvp-btn">立即前往</div></div></div><div class="cdc-header cdc-header--block" track="导航"><div class="cdc-header__placeholder"></div><div class="cdc-header__inner"><div class="cdc-header__top"><div class="cdc-header__top-left"><a href="/?from=20060&amp;from_column=20060" target="_blank" class="cdc-header__top-logo" hotrep="" track="腾讯云官网入口"><i>腾讯云</i></a><div class="cdc-header__top-line"></div><a href="/developer" class="cdc-header__top-logo community"><i>开发者社区</i></a><div class="cdc-header__activity"></div></div><div class="cdc-header__top-operates"><a href="/document/product?from=20702&amp;from_column=20702" target="_blank" class="cdc-header__link">文档</a><a href="/voc/?from=20703&amp;from_column=20703" target="_blank" class="cdc-header__link">建议反馈</a><a href="https://console.cloud.tencent.com?from=20063&amp;from_column=20063" target="_blank" class="cdc-header__link" track-click="{&quot;areaId&quot;:102001,&quot;subAreaId&quot;:1}">控制台</a></div></div><div class="cdc-header__bottom"><div class="cdc-header__bottom-nav"><a href="/developer" class="cdc-header__bottom-home">首页</a><div class="cdc-header__nav-list"><div class="cdc-header__nav-item">学习</div><div class="cdc-header__nav-item">活动</div><div class="cdc-header__nav-item">专区</div><div class="cdc-header__nav-item">工具</div></div><a href="https://cloud.tencent.com/tvp?from=20154&amp;from_column=20154" class="cdc-header__tvp" target="_blank">TVP</a><div class="cdc-header__activity"><a class="cdc-header__activity-tit" href="https://cloud.tencent.com/act?from=20061&amp;from_column=20061" target="_blank">最新优惠活动<div class="cdc-badge"><div class="cdc-badge-inner"><div class="cdc-badge-text"></div></div></div></a></div></div><div class="cdc-header__bottom-operates"><div class="cdc-header__search"><div class="cdc-search__wrap"><div class="cdc-search"><span class="cdc-search__text">文章/答案/技术大牛</span><button class="cdc-search__btn">搜索<i class="cdc-search__i search"></i></button></div><div class="cdc-search__dropdown"><div class="cdc-search__bar"><input type="text" class="cdc-search__bar-input" placeholder="文章/答案/技术大牛" value=""/><div class="cdc-search__bar-btns"><button class="cdc-search__btn">搜索<i class="cdc-search__i search"></i></button><button class="cdc-search__btn">关闭<i class="cdc-search__i clear"></i></button></div></div></div></div></div><div class="cdc-header__create"><span class="cdc-header__create-btn"><span class="cdc-svg-icon-con"><span class="cdc-svg-icon" style="width:16px;height:16px"><svg width="16" height="16" viewBox="0 0 16 16" fill="currentcolor" xmlns="http://www.w3.org/2000/svg"><path d="M14.2466 12.0145C14.1698 13.6258 12.8381 14.9131 11.2129 14.9131H11.1579H4.0927H4.03772C2.4125 14.9131 1.08014 13.6258 1.00334 12.0145H1V11.8668V4.07213V4.04627V3.89922H1.00334C1.08014 2.28732 2.4125 1 4.03772 1H9.6473V1.00069H10.0786L8.7688 2.10773H8.43888H7.7916H6.37904H4.03772C2.97234 2.10773 2.10445 2.9777 2.10445 4.04629V4.41869V4.4472V6.39498V11.4269V11.4309V11.8668C2.10445 12.9354 2.97234 13.8053 4.03772 13.8053H6.37904H8.87153H11.2129C12.2782 13.8053 13.1461 12.9355 13.1461 11.8668V11.466V11.454V9.5181V6.39364L14.2506 5.3051V11.8668V12.0145H14.2466ZM10.4324 7.15226L9.63146 7.99761C9.36577 8.2693 8.69326 8.95104 8.48066 9.17631C8.26726 9.40288 8.09039 9.58901 7.95061 9.73544C7.81079 9.88188 7.72667 9.96597 7.70083 9.98656C7.63321 10.0488 7.55703 10.1144 7.47022 10.1846C7.38412 10.2542 7.29404 10.3099 7.20063 10.3516C7.10722 10.4007 6.97072 10.459 6.79049 10.5305C6.61028 10.6001 6.42213 10.6676 6.22468 10.7339C6.02792 10.8002 5.84109 10.8571 5.66484 10.9061C5.48795 10.9538 5.3561 10.9863 5.2693 11.0009C5.08977 11.0214 4.96988 10.993 4.90956 10.9168C4.84931 10.8405 4.83276 10.7107 4.85924 10.5312C4.87315 10.4331 4.9043 10.292 4.95468 10.1078C5.00431 9.92297 5.05802 9.7315 5.11431 9.53341C5.1713 9.33526 5.22629 9.15179 5.27926 8.98484C5.33297 8.8179 5.37599 8.7026 5.40978 8.64032C5.44953 8.54357 5.49463 8.45413 5.54495 8.37399C5.59465 8.29379 5.66616 8.20503 5.75965 8.10766C5.79934 8.06588 5.89281 7.96649 6.03988 7.81018C6.18624 7.65311 6.80114 7.02774 7.02104 6.79783L7.75117 6.03524L8.56212 5.1899L10.6345 3.02466L12.5214 4.93874L10.4324 7.15226ZM13.816 3.58581C13.7166 3.68987 13.6272 3.78064 13.5483 3.85883C13.4694 3.93703 13.4006 4.0066 13.3423 4.06686C13.276 4.13643 13.2144 4.19738 13.1561 4.24903L11.2785 2.33569C11.3785 2.24025 11.4965 2.12565 11.6336 1.99115C11.7707 1.85668 11.8854 1.75061 11.9761 1.67242C12.0934 1.57708 12.2133 1.51013 12.3385 1.47109C12.4525 1.43529 12.5644 1.41805 12.6751 1.41876H12.7056C12.7665 1.42139 12.8268 1.42729 12.8851 1.43724C12.8838 1.4366 12.8811 1.43724 12.8798 1.4366C12.8811 1.4366 12.8838 1.4366 12.8851 1.43724C13.1376 1.48428 13.4019 1.62009 13.6265 1.83743C13.7511 1.95871 13.8524 2.09382 13.9259 2.23296C14.0346 2.43834 14.0863 2.65304 14.0763 2.8491C14.0763 2.87294 14.0783 2.89748 14.0783 2.92201C14.0783 3.03529 14.0571 3.14789 14.0154 3.26055C13.9737 3.37314 13.9067 3.48185 13.816 3.58581Z" fill="white"></path></svg></span></span>发布<span class="cdc-svg-icon-con cdc-header__create-btn-arrow"><span class="cdc-svg-icon" style="width:16px;height:16px"><svg width="16" height="16" viewBox="0 0 16 16" fill="currentcolor" xmlns="http://www.w3.org/2000/svg"><path d="M8.16377 4L9.57798 5.41421L14.5277 10.364L13.1135 11.7782L8.1638 6.829L3.21402 11.7782L1.7998 10.364L8.16377 4Z"></path></svg></span></span></span></div><div class="cdc-header__account"><div class="cdc-header__account-inner"><button class="cdc-btn cdc-header__account-btn cdc-btn--primary">登录/注册</button></div></div></div></div></div></div><div class="cdc-m-sticky-header is-hidden is-sticky"><div class="cdc-m-sticky-header__placeholder"></div><div class="cdc-m-sticky-header__main"><div class="cdc-m-sticky-header__con"><div class="cdc-m-sticky-header__trigger"></div><div class="cdc-m-header-article__menu"><div class="cdc-m-header-article__menu-mask"></div><div class="cdc-m-header-article__menu-side"><div class="cdc-m-header__sidebar"><div class="cdc-m-header__sidebar-top"><i class="cdc-m-header__sidebar-top__logo"></i><span class="cdc-m-header__sidebar-top__back"></span></div><div class="cdc-m-header__sidebar-menus"><a href="/developer" class="cdc-m-header__sidebar-menu link">首页</a><div class="tpm1-collapse"><div class="tpm1-collapse__panel"><header class="tpm1-collapse__panel-hd"><div class="tpm1-collapse__panel-title">学习</div></header></div><div class="tpm1-collapse__panel"><header class="tpm1-collapse__panel-hd"><div class="tpm1-collapse__panel-title">活动</div></header></div><div class="tpm1-collapse__panel"><header class="tpm1-collapse__panel-hd"><div class="tpm1-collapse__panel-title">专区</div></header></div><div class="tpm1-collapse__panel"><header class="tpm1-collapse__panel-hd"><div class="tpm1-collapse__panel-title">工具</div></header></div></div><a href="/tvp?from=20154&amp;from_column=20154" class="cdc-m-header__sidebar-menu link">TVP</a><a class="cdc-m-header__sidebar-activity" href="https://cloud.tencent.com/act?from=20061&amp;from_column=20061" target="_blank">最新优惠活动<div class="cdc-badge"><div class="cdc-badge-inner"><div class="cdc-badge-text"></div></div></div></a></div><div class="cdc-m-header__sidebar-back"><a href="/?from=20060&amp;from_column=20060" class="cdc-m-header__sidebar-back__link"><i></i><span>返回腾讯云官网</span></a></div></div></div></div><div class="cdc-m-sticky-header__author"><span class="cdc-avatar large circle" style="cursor:unset"><span class="cdc-avatar__inner" style="background-image:url(https://ask.qcloudimg.com/avatar/1148605/0awbobj21j.jpg)"></span></span><div class="cdc-m-sticky-header__author-name">红色石头</div></div></div><div class="cdc-m-sticky-header__extra"><div class="cdc-m-sticky-header__extra-icon"><i class="extra-search"></i></div><div class="cdc-m-sticky-header__extra-icon"><i class="extra-share"></i></div><div class="cdc-m-sticky-header__extra-operate"><div class="cdc-m-sticky-header__extra-icon"><i class="extra-man"></i></div></div></div></div></div><div class="cdc-m-header-article"><div class="cdc-m-header-article__placeholder"></div><div class="cdc-m-header-article__content"><div class="cdc-m-header-article__main"><div class="cdc-m-header-article__con"><div class="cdc-m-header-article__trigger"></div><div class="cdc-m-header-article__menu"><div class="cdc-m-header-article__menu-mask"></div><div class="cdc-m-header-article__menu-side"><div class="cdc-m-header__sidebar"><div class="cdc-m-header__sidebar-top"><i class="cdc-m-header__sidebar-top__logo"></i><span class="cdc-m-header__sidebar-top__back"></span></div><div class="cdc-m-header__sidebar-menus"><a href="/developer" class="cdc-m-header__sidebar-menu link">首页</a><div class="tpm1-collapse"><div class="tpm1-collapse__panel"><header class="tpm1-collapse__panel-hd"><div class="tpm1-collapse__panel-title">学习</div></header></div><div class="tpm1-collapse__panel"><header class="tpm1-collapse__panel-hd"><div class="tpm1-collapse__panel-title">活动</div></header></div><div class="tpm1-collapse__panel"><header class="tpm1-collapse__panel-hd"><div class="tpm1-collapse__panel-title">专区</div></header></div><div class="tpm1-collapse__panel"><header class="tpm1-collapse__panel-hd"><div class="tpm1-collapse__panel-title">工具</div></header></div></div><a href="/tvp?from=20154&amp;from_column=20154" class="cdc-m-header__sidebar-menu link">TVP</a><a class="cdc-m-header__sidebar-activity" href="https://cloud.tencent.com/act?from=20061&amp;from_column=20061" target="_blank">最新优惠活动<div class="cdc-badge"><div class="cdc-badge-inner"><div class="cdc-badge-text"></div></div></div></a></div><div class="cdc-m-header__sidebar-back"><a href="/?from=20060&amp;from_column=20060" class="cdc-m-header__sidebar-back__link"><i></i><span>返回腾讯云官网</span></a></div></div></div></div></div><div class="cdc-m-header-article__title"><div class="cdc-m-header-article__title-logo"></div></div><div class="cdc-m-header-article__extra"><div class="cdc-m-header-article__extra-icon"><i class="extra-search"></i></div><div class="cdc-m-header-article__extra-operate"><div class="cdc-m-header-article__extra-icon"><i class="extra-man"></i></div></div></div></div></div></div><div class="cdc-global__main"><div class="cdc-article__body"><div class="cdc-layout"><div class="cdc-layout__main"><div class="cdc-crumb mod-crumb"><div class="cdc-crumb__inner"><a class="cdc-crumb__item" href="/developer">社区首页</a><span class="cdc-crumb__split"> &gt;</span><a class="cdc-crumb__item" href="/developer/column">专栏</a><span class="cdc-crumb__split"> &gt;</span><span class="cdc-crumb__item current">我用 PyTorch 复现了 LeNet-5 神经网络（自定义数据集篇）！</span></div></div><div class="mod-article-content"><div class="mod-header"><div class="mod-header__top"><div class="mod-header__title"><h1 class="title-text">我用 PyTorch 复现了 LeNet-5 神经网络（自定义数据集篇）！</h1></div></div><div class="mod-article-source header"><div class="mod-article-source__main"><div class="mod-article-source__avatar"><img src="https://ask.qcloudimg.com/avatar/1148605/0awbobj21j.jpg" alt="作者头像"/></div><div class="mod-article-source__detail"><div class="mod-article-source__name"><span>红色石头</span></div></div><button class="cdc-btn mod-article-source__operate cdc-btn--primary"><span><i></i>关注</span></button></div></div><div class="mod-header__bottom"><div class="mod-header__detail"><div class="mod-header__date"><span class="date-text">发布<!-- -->于 <!-- -->2022-01-10 14:35:28</span></div><div class="mod-header__infos"><div class="cdc-icon__list"><span class="cdc-svg-icon-con"><span class="cdc-svg-icon" style="width:16px;height:16px"><svg width="16" height="16" viewBox="0 0 16 16" fill="currentcolor" xmlns="http://www.w3.org/2000/svg"><g id="icon-view" transform="translate(0.000000, 3.000000)" fill="currentcolor" fill-rule="nonzero"><path d="M15.885,4.68036 C14.9951,3.57569 11.7987,-0.004272 7.99883,-0.004272 C4.19895,-0.004272 1.02302,3.57569 0.112682,4.68036 C0.040058,4.77107 0.000488281,4.88381 0.000488281,5 C0.000488281,5.1162 0.040058,5.22894 0.112682,5.31964 C1.00767,6.42432 4.20407,10.0043 7.99883,10.0043 C11.7936,10.0043 14.9951,6.42432 15.885,5.31964 C15.9576,5.22894 15.9972,5.1162 15.9972,5 C15.9972,4.88381 15.9576,4.77107 15.885,4.68036 Z M7.99883,8.97632 C4.93029,8.97632 2.25555,6.25043 1.17644,4.99745 C2.25555,3.74446 4.95586,1.01857 7.99883,1.01857 C11.0418,1.01857 13.7421,3.74446 14.8314,4.99745 C13.7421,6.25043 11.0418,8.97632 7.99883,8.97632 Z" id="形状"></path><path d="M7.97304,2.55286 C7.49865,2.55286 7.03491,2.69353 6.64046,2.95709 C6.24602,3.22065 5.93859,3.59525 5.75704,4.03354 C5.5755,4.47182 5.528,4.95409 5.62055,5.41937 C5.7131,5.88465 5.94154,6.31203 6.27699,6.64748 C6.61244,6.98293 7.03982,7.21137 7.5051,7.30392 C7.97038,7.39647 8.45265,7.34897 8.89093,7.16743 C9.32922,6.98588 9.70382,6.67845 9.96738,6.28401 C10.2309,5.88956 10.3716,5.42582 10.3716,4.95143 C10.3716,4.31529 10.1189,3.7052 9.66909,3.25538 C9.21927,2.80556 8.60918,2.55286 7.97304,2.55286 Z M7.97304,6.32716 C7.70095,6.32716 7.43496,6.24647 7.20872,6.09531 C6.98249,5.94414 6.80616,5.72928 6.70203,5.4779 C6.59791,5.22652 6.57066,4.94991 6.62374,4.68304 C6.67683,4.41617 6.80785,4.17104 7.00025,3.97864 C7.19265,3.78625 7.43778,3.65522 7.70465,3.60214 C7.97151,3.54905 8.24813,3.5763 8.49951,3.68042 C8.75089,3.78455 8.96575,3.96088 9.11692,4.18712 C9.26808,4.41335 9.34877,4.67934 9.34877,4.95143 C9.35012,5.13295 9.31553,5.31295 9.247,5.48104 C9.17846,5.64913 9.07734,5.802 8.94946,5.93084 C8.82158,6.05967 8.66946,6.16192 8.50188,6.2317 C8.3343,6.30147 8.15457,6.33739 7.97304,6.33739 L7.97304,6.32716 Z" id="形状"></path></g></svg></span><span class="cdc-svg-icon-text">1.3K</span></span><span class="cdc-svg-icon-con is-comment"><span class="cdc-svg-icon" style="width:16px;height:16px"><svg width="16" height="16" viewBox="0 0 16 16" fill="currentcolor" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 13.414L5.58594 11H2V3H14V11H10.4141L8 13.414ZM5.17175 12L8 14.8282L10.8282 12H15V2H1V12H5.17175ZM4 6C3.44775 6 3 6.44769 3 7C3 7.55231 3.44775 8 4 8C4.55225 8 5 7.55231 5 7C5 6.44769 4.55225 6 4 6ZM7 7C7 6.44769 7.44775 6 8 6C8.55225 6 9 6.44769 9 7C9 7.55231 8.55225 8 8 8C7.44775 8 7 7.55231 7 7ZM12 6C11.4478 6 11 6.44769 11 7C11 7.55231 11.4478 8 12 8C12.5522 8 13 7.55231 13 7C13 6.44769 12.5522 6 12 6Z"></path></svg></span><span class="cdc-svg-icon-text">0</span></span></div></div><div class="mod-header__date is-mobile"><span class="date-text">发布<!-- -->于 <!-- -->2022-01-10 14:35:28</span></div></div><div class="mod-header__operates"><div class="mod-header__operate"><span class="cdc-svg-icon-con is-operate"><span class="cdc-svg-icon" style="width:16px;height:16px"><svg width="16" height="16" viewBox="0 0 16 16" fill="currentcolor" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.21101 2.54545C8.80733 1.81818 7.79814 1.81818 7.39446 2.54545L1.94481 12.3636C1.54113 13.0909 2.04573 14 2.85308 14H13.7524C14.5597 14 15.0643 13.0909 14.6607 12.3636L9.21101 2.54545ZM2.85308 12.9091L8.30273 3.09091L13.7524 12.9091H2.85308ZM8.00037 6H9.00037V10H8.00037V6ZM8.00037 11H9.00037V12H8.00037V11Z" fill="currentcolor"></path></svg></span><span class="cdc-svg-icon-text">举报</span></span></div></div></div><div><div class="mod-header__special"><div class="cdc-special-guide"><span><i class="cdc-special-guide-icon"></i>文章被收录于专栏：</span><a class="cdc-special-guide-name">红色石头的机器学习之路</a></div></div></div></div><div class="mod-content"><div class="mod-content__markdown"><div><div class="rno-markdown new-version rno-"><p>大家好，我是红色石头！</p><p>在上三篇文章：</p><p><span><em style="font-style:italic">这可能是神经网络 LeNet-5 最详细的解释了！</em></span></p><p><span><em style="font-style:italic">我用 PyTorch 复现了 LeNet-5 神经网络（MNIST 手写数据集篇）！</em></span></p><p><span><em style="font-style:italic">我用 PyTorch 复现了 LeNet-5 神经网络（CIFAR10 数据集篇）！</em></span></p><p>详细介绍了卷积神经网络 LeNet-5 的理论部分和使用 PyTorch 复现 LeNet-5 网络来解决 MNIST 数据集和 CIFAR10 数据集。然而大多数实际应用中，我们需要自己构建数据集，进行识别。因此，本文将讲解一下如何使用 LeNet-5 训练自己的数据。</p><p>正文开始！</p><p><strong>三、用 LeNet-5 训练自己的数据</strong></p><p>下面使用 LeNet-5 网络来训练本地的数据并进行测试。数据集是本地的 LED 数字 0-9，尺寸为 28x28 单通道，跟 MNIST 数据集类似。训练集 0-9 各 95 张，测试集 0~9 各 40 张。图片样例如图所示：</p><figure class=""><div class="rno-markdown-img-url" style="text-align:center"><div class="rno-markdown-img-url-inner" style="width:41.33%"><div style="width:100%"><img src="https://ask.qcloudimg.com/http-save/yehe-1148605/b8e29490dd5410611165a36ff794480b.png" alt="1ab8c291255c43b1ee5712b3ba9f06ae.png"/></div><div class="figure-desc">1ab8c291255c43b1ee5712b3ba9f06ae.png</div></div></div></figure><h3 id="cnjl6" name="3.1-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><strong>3.1 数据预处理</strong></h3><p><strong>制作图片数据的索引</strong></p><p>对于训练集和测试集，要分别制作对应的图片数据索引，即 train.txt 和 test.txt两个文件，每个 txt 中包含每个图片的目录和对应类别 class。示意图如下：</p><figure class=""><div class="rno-markdown-img-url" style="text-align:center"><div class="rno-markdown-img-url-inner" style="width:62.63%"><div style="width:100%"><img src="https://ask.qcloudimg.com/http-save/yehe-1148605/84e726924e163874d6e869359867d5e7.png" alt="24812e49aac530ac066198a835fb583d.png"/></div><div class="figure-desc">24812e49aac530ac066198a835fb583d.png</div></div></div></figure><p>制作图片数据索引的 python 脚本程序如下：</p><div class="rno-markdown-code"><div class="rno-markdown-code-toolbar"><div class="rno-markdown-code-toolbar-info"><div class="rno-markdown-code-toolbar-item is-type"><span class="is-m-hidden">代码语言：</span>javascript</div></div><div class="rno-markdown-code-toolbar-opt"><div class="rno-markdown-code-toolbar-copy"><i class="icon-copy"></i><span class="is-m-hidden">复制</span></div></div></div><div class="developer-code-block"><pre class="prism-token token line-numbers language-javascript"><code class="language-javascript" style="margin-left:0">import os


train_txt_path = os.path.join(&quot;data&quot;, &quot;LEDNUM&quot;, &quot;train.txt&quot;)
train_dir = os.path.join(&quot;data&quot;, &quot;LEDNUM&quot;, &quot;train_data&quot;)
valid_txt_path = os.path.join(&quot;data&quot;, &quot;LEDNUM&quot;, &quot;test.txt&quot;)
valid_dir = os.path.join(&quot;data&quot;, &quot;LEDNUM&quot;, &quot;test_data&quot;)


def gen_txt(txt_path, img_dir):
    f = open(txt_path, &#x27;w&#x27;)


    for root, s_dirs, _ in os.walk(img_dir, topdown=True):  # 获取 train文件下各文件夹名称
        for sub_dir in s_dirs:
            i_dir = os.path.join(root, sub_dir)             # 获取各类的文件夹 绝对路径
            img_list = os.listdir(i_dir)                    # 获取类别文件夹下所有png图片的路径
            for i in range(len(img_list)):
                if not img_list[i].endswith(&#x27;jpg&#x27;):         # 若不是png文件，跳过
                    continue
                label = img_list[i].split(&#x27;_&#x27;)[0]
                img_path = os.path.join(i_dir, img_list[i])
                line = img_path + &#x27; &#x27; + label + &#x27;\n&#x27;
                f.write(line)
    f.close()


if __name__ == &#x27;__main__&#x27;:
    gen_txt(train_txt_path, train_dir)
    gen_txt(valid_txt_path, valid_dir)</code></pre></div></div><p>运行脚本之后就在 ./data/LEDNUM/ 目录下生成 train.txt 和 test.txt 两个索引文件。</p><p><strong>构建Dataset子类</strong></p><p>pytorch 加载自己的数据集，需要写一个继承自 torch.utils.data 中 Dataset 类，并修改其中的 __init__ 方法、__getitem__ 方法、__len__ 方法。默认加载的都是图片，__init__ 的目的是得到一个包含数据和标签的 list，每个元素能找到图片位置和其对应标签。然后用 __getitem__ 方法得到每个元素的图像像素矩阵和标签，返回 img 和 label。</p><div class="rno-markdown-code"><div class="rno-markdown-code-toolbar"><div class="rno-markdown-code-toolbar-info"><div class="rno-markdown-code-toolbar-item is-type"><span class="is-m-hidden">代码语言：</span>javascript</div></div><div class="rno-markdown-code-toolbar-opt"><div class="rno-markdown-code-toolbar-copy"><i class="icon-copy"></i><span class="is-m-hidden">复制</span></div></div></div><div class="developer-code-block"><pre class="prism-token token line-numbers language-javascript"><code class="language-javascript" style="margin-left:0">from PIL import Image
from torch.utils.data import Dataset


class MyDataset(Dataset):
    def __init__(self, txt_path, transform = None, target_transform = None):
        fh = open(txt_path, &#x27;r&#x27;)
        imgs = []
        for line in fh:
            line = line.rstrip()
            words = line.split()
            imgs.append((words[0], int(words[1])))
            self.imgs = imgs 
            self.transform = transform
            self.target_transform = target_transform
    def __getitem__(self, index):
        fn, label = self.imgs[index]
        #img = Image.open(fn).convert(&#x27;RGB&#x27;) 
        img = Image.open(fn)
        if self.transform is not None:
            img = self.transform(img) 
        return img, label
    def __len__(self):
        return len(self.imgs)</code></pre></div></div><p>getitem 是核心函数。self.imgs 是一个 list，self.imgs[index] 是一个 str，包含图片路径，图片标签，这些信息是从上面生成的txt文件中读取；利用 Image.open 对图片进行读取，注意这里的 img 是单通道还是三通道的；self.transform(img) 对图片进行处理，这个 transform 里边可以实现减均值、除标准差、随机裁剪、旋转、翻转、放射变换等操作。</p><p>当 Mydataset构 建好，剩下的操作就交给 DataLoder，在 DataLoder 中，会触发 Mydataset 中的 getiterm 函数读取一张图片的数据和标签，并拼接成一个 batch 返回，作为模型真正的输入。</p><div class="rno-markdown-code"><div class="rno-markdown-code-toolbar"><div class="rno-markdown-code-toolbar-info"><div class="rno-markdown-code-toolbar-item is-type"><span class="is-m-hidden">代码语言：</span>javascript</div></div><div class="rno-markdown-code-toolbar-opt"><div class="rno-markdown-code-toolbar-copy"><i class="icon-copy"></i><span class="is-m-hidden">复制</span></div></div></div><div class="developer-code-block"><pre class="prism-token token line-numbers language-javascript"><code class="language-javascript" style="margin-left:0">pipline_train = transforms.Compose([
    #随机旋转图片
    transforms.RandomHorizontalFlip(),
    #将图片尺寸resize到32x32
    transforms.Resize((32,32)),
    #将图片转化为Tensor格式
    transforms.ToTensor(),
    #正则化(当模型出现过拟合的情况时，用来降低模型的复杂度)
    transforms.Normalize((0.1307,),(0.3081,))    
])
pipline_test = transforms.Compose([
    #将图片尺寸resize到32x32
    transforms.Resize((32,32)),
    transforms.ToTensor(),
    transforms.Normalize((0.1307,),(0.3081,))
])
train_data = MyDataset(&#x27;./data/LEDNUM/train.txt&#x27;, transform=pipline_train)
test_data = MyDataset(&#x27;./data/LEDNUM/test.txt&#x27;, transform=pipline_test)


#train_data 和test_data包含多有的训练与测试数据，调用DataLoader批量加载
trainloader = torch.utils.data.DataLoader(dataset=train_data, batch_size=8, shuffle=True)
testloader = torch.utils.data.DataLoader(dataset=test_data, batch_size=4, shuffle=False)</code></pre></div></div><p><strong>3.2 搭建 LeNet-5 神经网络结构</strong></p><div class="rno-markdown-code"><div class="rno-markdown-code-toolbar"><div class="rno-markdown-code-toolbar-info"><div class="rno-markdown-code-toolbar-item is-type"><span class="is-m-hidden">代码语言：</span>javascript</div></div><div class="rno-markdown-code-toolbar-opt"><div class="rno-markdown-code-toolbar-copy"><i class="icon-copy"></i><span class="is-m-hidden">复制</span></div></div></div><div class="developer-code-block"><pre class="prism-token token line-numbers language-javascript"><code class="language-javascript" style="margin-left:0">class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5) 
        self.relu = nn.ReLU()
        self.maxpool1 = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.maxpool2 = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(16*5*5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)


    def forward(self, x):
        x = self.conv1(x)
        x = self.relu(x)
        x = self.maxpool1(x)
        x = self.conv2(x)
        x = self.maxpool2(x)
        x = x.view(-1, 16*5*5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        output = F.log_softmax(x, dim=1)
        return output</code></pre></div></div><p><strong>3.3 将定义好的网络结构搭载到 GPU/CPU，并定义优化器</strong></p><div class="rno-markdown-code"><div class="rno-markdown-code-toolbar"><div class="rno-markdown-code-toolbar-info"><div class="rno-markdown-code-toolbar-item is-type"><span class="is-m-hidden">代码语言：</span>javascript</div></div><div class="rno-markdown-code-toolbar-opt"><div class="rno-markdown-code-toolbar-copy"><i class="icon-copy"></i><span class="is-m-hidden">复制</span></div></div></div><div class="developer-code-block"><pre class="prism-token token line-numbers language-javascript"><code class="language-javascript" style="margin-left:0">#创建模型，部署gpu
device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
model = LeNet().to(device)
#定义优化器
optimizer = optim.Adam(model.parameters(), lr=0.001)</code></pre></div></div><p><strong>3.4 定义训练函数</strong></p><div class="rno-markdown-code"><div class="rno-markdown-code-toolbar"><div class="rno-markdown-code-toolbar-info"><div class="rno-markdown-code-toolbar-item is-type"><span class="is-m-hidden">代码语言：</span>javascript</div></div><div class="rno-markdown-code-toolbar-opt"><div class="rno-markdown-code-toolbar-copy"><i class="icon-copy"></i><span class="is-m-hidden">复制</span></div></div></div><div class="developer-code-block"><pre class="prism-token token line-numbers language-javascript"><code class="language-javascript" style="margin-left:0">def train_runner(model, device, trainloader, optimizer, epoch):
    #训练模型, 启用 BatchNormalization 和 Dropout, 将BatchNormalization和Dropout置为True
    model.train()
    total = 0
    correct =0.0


    #enumerate迭代已加载的数据集,同时获取数据和数据下标
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        #把模型部署到device上
        inputs, labels = inputs.to(device), labels.to(device)
        #初始化梯度
        optimizer.zero_grad()
        #保存训练结果
        outputs = model(inputs)
        #计算损失和
        #多分类情况通常使用cross_entropy(交叉熵损失函数), 而对于二分类问题, 通常使用sigmod
        loss = F.cross_entropy(outputs, labels)
        #获取最大概率的预测结果
        #dim=1表示返回每一行的最大值对应的列下标
        predict = outputs.argmax(dim=1)
        total += labels.size(0)
        correct += (predict == labels).sum().item()
        #反向传播
        loss.backward()
        #更新参数
        optimizer.step()
        if i % 100 == 0:
            #loss.item()表示当前loss的数值
            print(&quot;Train Epoch{} \t Loss: {:.6f}, accuracy: {:.6f}%&quot;.format(epoch, loss.item(), 100*(correct/total)))
            Loss.append(loss.item())
            Accuracy.append(correct/total)
    return loss.item(), correct/total</code></pre></div></div><p><strong>3.5 定义测试函数</strong></p><div class="rno-markdown-code"><div class="rno-markdown-code-toolbar"><div class="rno-markdown-code-toolbar-info"><div class="rno-markdown-code-toolbar-item is-type"><span class="is-m-hidden">代码语言：</span>javascript</div></div><div class="rno-markdown-code-toolbar-opt"><div class="rno-markdown-code-toolbar-copy"><i class="icon-copy"></i><span class="is-m-hidden">复制</span></div></div></div><div class="developer-code-block"><pre class="prism-token token line-numbers language-javascript"><code class="language-javascript" style="margin-left:0">def test_runner(model, device, testloader):
    #模型验证, 必须要写, 否则只要有输入数据, 即使不训练, 它也会改变权值
    #因为调用eval()将不启用 BatchNormalization 和 Dropout, BatchNormalization和Dropout置为False
    model.eval()
    #统计模型正确率, 设置初始值
    correct = 0.0
    test_loss = 0.0
    total = 0
    #torch.no_grad将不会计算梯度, 也不会进行反向传播
    with torch.no_grad():
        for data, label in testloader:
            data, label = data.to(device), label.to(device)
            output = model(data)
            test_loss += F.cross_entropy(output, label).item()
            predict = output.argmax(dim=1)
            #计算正确数量
            total += label.size(0)
            correct += (predict == label).sum().item()
        #计算损失值
        print(&quot;test_avarage_loss: {:.6f}, accuracy: {:.6f}%&quot;.format(test_loss/total, 100*(correct/total)))</code></pre></div></div><p><strong>3.6 运行</strong></p><div class="rno-markdown-code"><div class="rno-markdown-code-toolbar"><div class="rno-markdown-code-toolbar-info"><div class="rno-markdown-code-toolbar-item is-type"><span class="is-m-hidden">代码语言：</span>javascript</div></div><div class="rno-markdown-code-toolbar-opt"><div class="rno-markdown-code-toolbar-copy"><i class="icon-copy"></i><span class="is-m-hidden">复制</span></div></div></div><div class="developer-code-block"><pre class="prism-token token line-numbers language-javascript"><code class="language-javascript" style="margin-left:0">#调用
epoch = 5
Loss = []
Accuracy = []
for epoch in range(1, epoch+1):
    print(&quot;start_time&quot;,time.strftime(&#x27;%Y-%m-%d %H:%M:%S&#x27;,time.localtime(time.time())))
    loss, acc = train_runner(model, device, trainloader, optimizer, epoch)
    Loss.append(loss)
    Accuracy.append(acc)
    test_runner(model, device, testloader)
    print(&quot;end_time: &quot;,time.strftime(&#x27;%Y-%m-%d %H:%M:%S&#x27;,time.localtime(time.time())),&#x27;\n&#x27;)


print(&#x27;Finished Training&#x27;)
plt.subplot(2,1,1)
plt.plot(Loss)
plt.title(&#x27;Loss&#x27;)
plt.show()
plt.subplot(2,1,2)
plt.plot(Accuracy)
plt.title(&#x27;Accuracy&#x27;)
plt.show()</code></pre></div></div><figure class=""><div class="rno-markdown-img-url" style="text-align:center"><div class="rno-markdown-img-url-inner" style="width:53.96%"><div style="width:100%"><img src="https://ask.qcloudimg.com/http-save/yehe-1148605/29a988116d69d620eceff20414d5e37e.png" alt="7cdaf9ae9f1ee7f7285d6ec85e73ced7.png"/></div><div class="figure-desc">7cdaf9ae9f1ee7f7285d6ec85e73ced7.png</div></div></div></figure><p>经历 5 次 epoch 的 loss 和 accuracy 曲线如下：</p><figure class=""><div class="rno-markdown-img-url" style="text-align:center"><div class="rno-markdown-img-url-inner" style="width:48.09%"><div style="width:100%"><img src="https://ask.qcloudimg.com/http-save/yehe-1148605/e0ceee28af65711d7bf7707ebda6f80d.png" alt="e2ac213790e9b6efb5f4bc938968fd0b.png"/></div><div class="figure-desc">e2ac213790e9b6efb5f4bc938968fd0b.png</div></div></div></figure><p><strong>3.7 模型保存</strong></p><div class="rno-markdown-code"><div class="rno-markdown-code-toolbar"><div class="rno-markdown-code-toolbar-info"><div class="rno-markdown-code-toolbar-item is-type"><span class="is-m-hidden">代码语言：</span>javascript</div></div><div class="rno-markdown-code-toolbar-opt"><div class="rno-markdown-code-toolbar-copy"><i class="icon-copy"></i><span class="is-m-hidden">复制</span></div></div></div><div class="developer-code-block"><pre class="prism-token token line-numbers language-javascript"><code class="language-javascript" style="margin-left:0">torch.save(model, &#x27;./models/model-mine.pth&#x27;) #保存模型</code></pre></div></div><p><strong>3.8 模型测试</strong></p><p>下面使用上面训练的模型对一张 LED 图片进行测试。</p><div class="rno-markdown-code"><div class="rno-markdown-code-toolbar"><div class="rno-markdown-code-toolbar-info"><div class="rno-markdown-code-toolbar-item is-type"><span class="is-m-hidden">代码语言：</span>javascript</div></div><div class="rno-markdown-code-toolbar-opt"><div class="rno-markdown-code-toolbar-copy"><i class="icon-copy"></i><span class="is-m-hidden">复制</span></div></div></div><div class="developer-code-block"><pre class="prism-token token line-numbers language-javascript"><code class="language-javascript" style="margin-left:0">from PIL import Image
import numpy as np


if __name__ == &#x27;__main__&#x27;:
    device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)
    model = torch.load(&#x27;./models/model-mine.pth&#x27;) #加载模型
    model = model.to(device)
    model.eval()    #把模型转为test模式


    #读取要预测的图片
    # 读取要预测的图片
    img = Image.open(&quot;./images/test_led.jpg&quot;) # 读取图像
    #img.show()
    plt.imshow(img,cmap=&quot;gray&quot;) # 显示图片
    plt.axis(&#x27;off&#x27;) # 不显示坐标轴
    plt.show()


    # 导入图片，图片扩展后为[1，1，32，32]
    trans = transforms.Compose(
        [
            #将图片尺寸resize到32x32
            transforms.Resize((32,32)),
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
    img = trans(img)
    img = img.to(device)
    img = img.unsqueeze(0)  #图片扩展多一维,因为输入到保存的模型中是4维的[batch_size,通道,长，宽]，而普通图片只有三维，[通道,长，宽]


    # 预测 
    output = model(img)
    prob = F.softmax(output,dim=1) #prob是10个分类的概率
    print(&quot;概率：&quot;,prob)
    value, predicted = torch.max(output.data, 1)
    predict = output.argmax(dim=1)
    print(&quot;预测类别：&quot;,predict.item())</code></pre></div></div><figure class=""><div class="rno-markdown-img-url" style="text-align:center"><div class="rno-markdown-img-url-inner" style="width:28.45%"><div style="width:100%"><img src="https://ask.qcloudimg.com/http-save/yehe-1148605/277a6b5ccbb723001f3e989dcbe56337.png" alt="d9fb2ce11a26330d2f7f3496774c6768.png"/></div><div class="figure-desc">d9fb2ce11a26330d2f7f3496774c6768.png</div></div></div></figure><div class="rno-markdown-code"><div class="rno-markdown-code-toolbar"><div class="rno-markdown-code-toolbar-info"><div class="rno-markdown-code-toolbar-item is-type"><span class="is-m-hidden">代码语言：</span>javascript</div></div><div class="rno-markdown-code-toolbar-opt"><div class="rno-markdown-code-toolbar-copy"><i class="icon-copy"></i><span class="is-m-hidden">复制</span></div></div></div><div class="developer-code-block"><pre class="prism-token token line-numbers language-javascript"><code class="language-javascript" style="margin-left:0">概率：tensor([[7.2506e-11, 7.0065e-18, 7.1749e-06, 7.4855e-13, 7.3532e-08, 8.5405e-17,
         2.5753e-15, 9.7887e-10, 2.7855e-05, 9.9996e-01]],
       grad_fn=&lt;SoftmaxBackward&gt;)
预测类别：9</code></pre></div></div><p>模型预测结果正确！</p><p>以上就是 PyTorch 构建 LeNet-5 卷积神经网络并用它来识别自定义数据集的例子。全文的代码都是可以顺利运行的，建议大家自己跑一边。</p><p><strong>总结：</strong></p><p>是我们目前分别复现了 LeNet-5 来识别 MNIST、CIFAR10 和自定义数据集，基本上涵盖了基于 PyToch 的 LeNet-5 实战的所有内容。希望对大家有所帮助！</p><p>所有完整的代码我都放在 GitHub 上，GitHub地址为：</p><p><em style="font-style:italic">https://github.com/RedstoneWill/ObjectDetectionLearner/tree/main/LeNet-5</em></p></div></div></div><div class="mod-content__source"><div class="mod-content__source-inner"><div class="mod-content__source-title">本文参与 <a href="/developer/support-plan" target="_blank">腾讯云自媒体同步曝光计划</a>，分享自作者个人站点/博客。</div><div class="mod-content__source-desc"> 原始发表：2022/01/04 ，<!-- -->如有侵权请联系 <a href="mailto:cloudcommunity@tencent.com">cloudcommunity@tencent.com</a> 删除</div></div><div class="mod-content__source-btn"><button class="cdc-btn cdc-btn--hole">前往查看</button></div></div><div class="mod-statement-m"><div class="cdc-tag__list mod-content__tags" track-click=""><div class="cdc-tag" track-click="" track-exposure=""><a class="cdc-tag__inner" href="/developer/tag/10735" target="_blank">pytorch</a></div><div class="cdc-tag" track-click="" track-exposure=""><a class="cdc-tag__inner" href="/developer/tag/10332" target="_blank">神经网络</a></div><div class="cdc-tag" track-click="" track-exposure=""><a class="cdc-tag__inner" href="/developer/tag/10690" target="_blank">卷积神经网络</a></div><div class="cdc-tag" track-click="" track-exposure=""><a class="cdc-tag__inner" href="/developer/tag/10497" target="_blank">腾讯云测试服务</a></div><div class="cdc-tag" track-click="" track-exposure=""><a class="cdc-tag__inner" href="/developer/tag/10284" target="_blank">github</a></div></div><div class="mod-content__statement"><p>本文分享自 <span>作者个人站点/博客</span> <span style="color:#0052d9;cursor:pointer">前往查看</span></p><p>如有侵权，请联系 <a href="mailto:cloudcommunity@tencent.com">cloudcommunity@tencent.com</a> 删除。</p><p class="mod-content__statement-tip">本文参与 <a href="/developer/support-plan" target="_blank">腾讯云自媒体同步曝光计划</a>  ，欢迎热爱写作的你一起参与！</p></div></div><div class="cdc-tag__list mod-content__tags" track-click=""><div class="cdc-tag" track-click="" track-exposure=""><a class="cdc-tag__inner" href="/developer/tag/10735" target="_blank">pytorch</a></div><div class="cdc-tag" track-click="" track-exposure=""><a class="cdc-tag__inner" href="/developer/tag/10332" target="_blank">神经网络</a></div><div class="cdc-tag" track-click="" track-exposure=""><a class="cdc-tag__inner" href="/developer/tag/10690" target="_blank">卷积神经网络</a></div><div class="cdc-tag" track-click="" track-exposure=""><a class="cdc-tag__inner" href="/developer/tag/10497" target="_blank">腾讯云测试服务</a></div><div class="cdc-tag" track-click="" track-exposure=""><a class="cdc-tag__inner" href="/developer/tag/10284" target="_blank">github</a></div></div></div></div><div class="mod-article-content is-pill-hidden"><div class="mod-comment"><div class="mod-relevant__title">评论</div><div class="cdc-comment-response"><div class="cdc-comment-response-single-edit not-logged"><div class="cdc-comment-response-single-edit__inner"><span class="cdc-avatar cdc-comment-response-single-edit__avatar cdc-comment__avatar circle"><span class="cdc-avatar__inner" style="background-image:url(https://qcloudimg.tencent-cloud.cn/raw/2eca91c9c29816ff056d22815949d83c.png)" target="_blank"></span></span><div class="cdc-comment-response-single-edit__main"><span>登录</span>后参与评论</div></div></div><div class="cdc-comment-response__toolbar"><div class="cdc-comment-response__number">0<!-- --> 条评论</div><div class="cdc-comment-response__segment"><div class="cdc-comment-response__segment-item is-active">热度</div><div class="cdc-comment-response__segment-item">最新</div></div></div><div class="cdc-comment-response-inner"><div class="cdc-comment-response__body"><div><div class="cdc-loading"><div class="cdc-loading__inner"><div class="cdc-loading__item one"></div><div class="cdc-loading__item two"></div><div class="cdc-loading__item three"></div></div></div></div></div></div><div class="cdc-operate-footer"><div class="cdc-operate-footer__inner"><div class="cdc-operate-footer__toggle is-logout"><div class="cdc-operate-footer__toggle-text"><span>登录 </span>后参与评论</div></div></div></div></div></div></div><div class="mod-article-content recommend"><div class="mod-relevant" qct-area="推荐阅读" qct-exposure=""><div class="mod-relevant__title recommend-read">推荐阅读</div><div class="t-divider t-divider--horizontal" style="margin-bottom:0;margin-top:10px"></div></div></div></div><div class="cdc-layout__side"><div class="cdc-personal-info2 mod-author"><div class="cdc-personal-info2__inner"><div class="cdc-personal-info2__detail"><div class="cdc-personal-info2__main"><div class="cdc-personal-info2__name"><a href="/developer/user/1148605" target="_blank" class="cdc-personal-info2__name-text"></a></div><div class="cdc-personal-info2__level"><div class="cdc-personal-info2__level-number">LV.</div><div class="cdc-emblems cdc-personal-info2__level-emblems"></div></div><div class="cdc-personal-info2__position"></div></div><div class="cdc-personal-info2__avatar"></div></div><div class="cdc-personal-info2__list"><a class="cdc-personal-info2__item" href="/developer/user/undefined/articles" target="_blank"><div class="cdc-personal-info2__item-text">文章</div><div class="cdc-personal-info2__item-number">0</div></a><a class="cdc-personal-info2__item" href="/developer/user/undefined" target="_blank"><div class="cdc-personal-info2__item-text">获赞</div><div class="cdc-personal-info2__item-number">0</div></a></div></div></div><div class="mod-sticky-act"><div class="cdc-directory is-just-commercial"><div class="cdc-directory__wrap"><div class="cdc-directory__inner"><div class="cdc-directory__hd">目录</div><div class="cdc-directory__bd"><div class="cdc-directory__bd-box"><ul class="cdc-directory__list level-1"><li class="cdc-directory__item"><span class="cdc-directory__target" id="menu-cnjl6">3.1 数据预处理</span></li></ul></div></div></div></div></div><div class="cdc-mod-product2"><div class="cdc-card" qct-exposure="" qct-area="相关产品与服务"><div class="cdc-card__inner"><div class="cdc-card__hd"><div class="cdc-card__title">相关产品与服务</div></div><div class="cdc-card__bd"><div class="cdc-product-info2__list"><div class="cdc-product-info2"><div class="cdc-product-info2__card-main"><div class="cdc-product-info2__card-name">内容识别</div><div class="cdc-product-info2__card-desc">内容识别（Content Recognition，CR）是腾讯云数据万象推出的对图片内容进行识别、理解的服务，集成腾讯云 AI 的多种强大功能，对存储在腾讯云对象存储 COS 的数据提供图片标签、图片修复、二维码识别、语音识别、质量评估等增值服务。</div><div class="cdc-product-info2__card-list"><a target="_blank" href="https://cloud.tencent.com/product/crg?from=21341&amp;from_column=21341"><i class="product-icon introduce-icon"></i>产品介绍</a><a target="_blank" href="https://cloud.tencent.com/document/product/1239?from=21342&amp;from_column=21342"><i class="product-icon document-icon"></i>产品文档</a></div></div><div class="cdc-product-info2__activity"><a target="_blank" href="https://cloud.tencent.com/act/pro/Featured?from=21344&amp;from_column=21344"><i class="hot-icon"></i>精选特惠 用云无忧</a></div></div></div></div></div></div></div></div></div></div></div></div><div class="cdc-widget-global"><div class="cdc-widget-global__btn code"><div class="cdc-widget-global__btn-tag">领券</div></div><div class="cdc-widget-global__btn top" style="visibility:hidden"></div></div><div class="cdc-footer"><div class="cdc-footer__inner"><div class="cdc-footer__main"><div class="cdc-footer__website"><ul class="cdc-footer__website-group"><li class="cdc-footer__website-column"><div class="cdc-footer__website-box"><h3 class="cdc-footer__website-title">社区</h3><ul class="cdc-footer__website-list"><li class="cdc-footer__website-item"><a href="/developer/column">技术文章</a></li><li class="cdc-footer__website-item"><a href="/developer/ask">技术问答</a></li><li class="cdc-footer__website-item"><a href="/developer/salon">技术沙龙</a></li><li class="cdc-footer__website-item"><a href="/developer/video">技术视频</a></li><li class="cdc-footer__website-item"><a href="/developer/learning">学习中心</a></li><li class="cdc-footer__website-item"><a href="/developer/techpedia">技术百科</a></li><li class="cdc-footer__website-item"><a href="/developer/zone/list">技术专区</a></li></ul></div></li><li class="cdc-footer__website-column"><div class="cdc-footer__website-box"><h3 class="cdc-footer__website-title">活动</h3><ul class="cdc-footer__website-list"><li class="cdc-footer__website-item"><a href="/developer/support-plan">自媒体同步曝光计划</a></li><li class="cdc-footer__website-item"><a href="/developer/support-plan-invitation">邀请作者入驻</a></li><li class="cdc-footer__website-item"><a href="/developer/article/1535830">自荐上首页</a></li><li class="cdc-footer__website-item"><a href="/developer/competition">技术竞赛</a></li></ul></div></li><li class="cdc-footer__website-column"><div class="cdc-footer__website-box"><h3 class="cdc-footer__website-title">资源</h3><ul class="cdc-footer__website-list"><li class="cdc-footer__website-item"><a href="/developer/specials">技术周刊</a></li><li class="cdc-footer__website-item"><a href="/developer/tags">社区标签</a></li><li class="cdc-footer__website-item"><a href="/developer/devdocs">开发者手册</a></li><li class="cdc-footer__website-item"><a href="/lab?from=20064&amp;from_column=20064">开发者实验室</a></li></ul></div></li><li class="cdc-footer__website-column"><div class="cdc-footer__website-box"><h3 class="cdc-footer__website-title">关于</h3><ul class="cdc-footer__website-list"><li class="cdc-footer__website-item"><a rel="nofollow" href="/developer/article/1006434">社区规范</a></li><li class="cdc-footer__website-item"><a rel="nofollow" href="/developer/article/1006435">免责声明</a></li><li class="cdc-footer__website-item"><a rel="nofollow" href="mailto:cloudcommunity@tencent.com">联系我们</a></li><li class="cdc-footer__website-item"><a rel="nofollow" href="/developer/friendlink">友情链接</a></li></ul></div></li></ul></div><div class="cdc-footer__qr"><h3 class="cdc-footer__qr-title">腾讯云开发者</h3><div class="cdc-footer__qr-object"><img src="https://qcloudimg.tencent-cloud.cn/raw/a8907230cd5be483497c7e90b061b861.png?imageView2/2/w/152" class="cdc-footer__qr-image" alt="扫码关注腾讯云开发者"/></div><div class="cdc-footer__qr-infos"><p class="cdc-footer__qr-info"><span class="cdc-footer__qr-text">扫码关注腾讯云开发者</span></p><p class="cdc-footer__qr-info"><span class="cdc-footer__qr-text">领取腾讯云代金券</span></p></div></div></div><div class="cdc-footer__recommend"><div class="cdc-footer__recommend-rows"><div class="cdc-footer__recommend-cell"><h3 class="cdc-footer__recommend-title">热门产品</h3><div class="cdc-footer__recommend-wrap"><ul class="cdc-footer__recommend-list"><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="https://dnspod.cloud.tencent.com?from=20064&amp;from_column=20064">域名注册</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/cvm?from=20064&amp;from_column=20064">云服务器</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/tbaas?from=20064&amp;from_column=20064">区块链服务</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/mq?from=20064&amp;from_column=20064">消息队列</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/dsa?from=20064&amp;from_column=20064">网络加速</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/tencentdb-catalog?from=20064&amp;from_column=20064">云数据库</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/cns?from=20064&amp;from_column=20064">域名解析</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/cos?from=20064&amp;from_column=20064">云存储</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/css?from=20064&amp;from_column=20064">视频直播</a></li></ul></div></div><div class="cdc-footer__recommend-cell"><h3 class="cdc-footer__recommend-title">热门推荐</h3><div class="cdc-footer__recommend-wrap"><ul class="cdc-footer__recommend-list"><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/facerecognition?from=20064&amp;from_column=20064">人脸识别</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/tm?from=20064&amp;from_column=20064">腾讯会议</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/act/pro/enterprise2019?from=20064&amp;from_column=20064">企业云</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/cdn-scd?from=20064&amp;from_column=20064">CDN加速</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/trtc?from=20064&amp;from_column=20064">视频通话</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/tiia?from=20064&amp;from_column=20064">图像分析</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/cdb?from=20064&amp;from_column=20064">MySQL 数据库</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/symantecssl?from=20064&amp;from_column=20064">SSL 证书</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/asr?from=20064&amp;from_column=20064">语音识别</a></li></ul></div></div><div class="cdc-footer__recommend-cell"><h3 class="cdc-footer__recommend-title">更多推荐</h3><div class="cdc-footer__recommend-wrap"><ul class="cdc-footer__recommend-list"><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/solution/data_protection?from=20064&amp;from_column=20064">数据安全</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/clb?from=20064&amp;from_column=20064">负载均衡</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/sms?from=20064&amp;from_column=20064">短信</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/ocr?from=20064&amp;from_column=20064">文字识别</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/vod?from=20064&amp;from_column=20064">云点播</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="https://tm.cloud.tencent.com?from=20064&amp;from_column=20064">商标注册</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/solution/la?from=20064&amp;from_column=20064">小程序开发</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/cat?from=20064&amp;from_column=20064">网站监控</a></li><li class="cdc-footer__recommend-item"><a class="com-2-footer-recommend-link" href="/product/cdm?from=20064&amp;from_column=20064">数据迁移</a></li></ul></div></div></div></div><div class="cdc-footer__copyright"><div class="cdc-footer__copyright-text"><p>Copyright © 2013 - <!-- -->2024<!-- --> Tencent Cloud. All Rights Reserved. 腾讯云 版权所有 </p><p>深圳市腾讯计算机系统有限公司 ICP备案/许可证号：<a href="https://beian.miit.gov.cn/#/Integrated/index" target="_blank">粤B2-20090059 </a><a href="https://www.beian.gov.cn/portal/index.do" target="_blank">深公网安备号 44030502008569</a></p><p>腾讯云计算（北京）有限责任公司 京ICP证150476号 |  <a href="https://beian.miit.gov.cn/#/Integrated/index" target="_blank">京ICP备11018762号</a> <!-- -->|<!-- --> <a href="https://www.beian.gov.cn/portal/index.do" target="_blank">京公网安备号11010802020287</a></p></div></div></div></div><div style="display:none"><a href="/developer/ask/archives.html">问题归档</a><a href="/developer/column/archives.html">专栏文章</a><a href="/developer/news/archives.html">快讯文章归档</a><a href="/developer/information/all.html">关键词归档</a><a href="/developer/devdocs/archives.html">开发者手册归档</a><a href="/developer/devdocs/sections_p1.html">开发者手册 Section 归档</a></div><div class="cdc-m-footer"><div class="cdc-m-footer__inner"><div class="cdc-m-footer__copyright"><p>Copyright © 2013 - <!-- -->2024<!-- --> Tencent Cloud.</p><p>All Rights Reserved. 腾讯云 版权所有</p></div></div></div><div class="cdc-operate-footer"><div class="cdc-operate-footer__inner"><div class="cdc-operate-footer__toggle is-logout"><div class="cdc-operate-footer__toggle-text"><span>登录 </span>后参与评论</div></div><div class="cdc-operate-footer__operations"><div class="cdc-operate-footer__operate"><i class="cdc-operate-footer__operate-icon comment"></i></div><div class="cdc-operate-footer__operate"><i class="cdc-operate-footer__operate-icon book"></i></div><div class="cdc-operate-footer__operate"><i class="cdc-operate-footer__operate-icon menu"></i></div><div class="cdc-operate-footer__operate"><i class="cdc-operate-footer__operate-icon more"></i></div></div></div></div><div class="cdc-suspend-pill"><div class="cdc-suspend-pill__inner"><button class="cdc-icon-btn cdc-suspend-pill__item emoji cdc-icon-btn--text"><div class="emoji-item"><span class="emoji-item-icon fire"></span></div><span class="cdc-suspend-pill__item-number">0</span></button><button class="cdc-icon-btn cdc-suspend-pill__item like cdc-icon-btn--text"><span class="cdc-svg-icon-con"><span class="cdc-svg-icon" style="width:24px;height:24px"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentcolor"><path fill-rule="evenodd" clip-rule="evenodd" d="M17.5 11.25C17.5 11.9404 16.9404 12.5 16.25 12.5C15.5596 12.5 15 11.9404 15 11.25C15 10.5596 15.5596 10 16.25 10C16.9404 10 17.5 10.5596 17.5 11.25Z M12.25 12.5C12.9404 12.5 13.5 11.9404 13.5 11.25C13.5 10.5596 12.9404 10 12.25 10C11.5596 10 11 10.5596 11 11.25C11 11.9404 11.5596 12.5 12.25 12.5Z M8.25 12.5C8.94036 12.5 9.5 11.9404 9.5 11.25C9.5 10.5596 8.94036 10 8.25 10C7.55964 10 7 10.5596 7 11.25C7 11.9404 7.55964 12.5 8.25 12.5Z M5 3C3.34315 3 2 4.34315 2 6V16C2 17.6569 3.34315 19 5 19H8.34311L10.5858 21.2426C11.3668 22.0237 12.6331 22.0237 13.4142 21.2426L15.6568 19H19C20.6569 19 22 17.6569 22 16V6C22 4.34315 20.6569 3 19 3H5ZM4 6C4 5.44772 4.44772 5 5 5H19C19.5523 5 20 5.44772 20 6V16C20 16.5523 19.5523 17 19 17H14.8284L12 19.8284L9.17154 17H5C4.44772 17 4 16.5523 4 16V6Z"></path></svg></span></span><span class="cdc-suspend-pill__item-number">0</span></button><button class="cdc-icon-btn cdc-suspend-pill__item collect cdc-icon-btn--text" qct-area="收藏文章" qct-click=""><span class="cdc-svg-icon-con"><span class="cdc-svg-icon" style="width:24px;height:24px"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M10.2057 3.11487C10.9393 1.62838 13.059 1.62838 13.7927 3.11487L15.9724 7.53141L20.8463 8.23963C22.4867 8.478 23.1418 10.4939 21.9547 11.651L18.4279 15.0888L19.2605 19.9431C19.5407 21.5769 17.8258 22.8228 16.3586 22.0514L11.9992 19.7596L7.63981 22.0514C6.17255 22.8228 4.45769 21.5769 4.73791 19.9431L5.57048 15.0888L2.04366 11.651C0.856629 10.4939 1.51165 8.478 3.15209 8.23963L8.02603 7.53141L10.2057 3.11487ZM11.9992 4L9.8195 8.41654C9.52818 9.00683 8.96504 9.41597 8.31363 9.51062L3.43969 10.2188L6.9665 13.6566C7.43787 14.1161 7.65297 14.7781 7.5417 15.4269L6.70913 20.2812L11.0685 17.9893C11.6512 17.683 12.3472 17.683 12.9299 17.9893L17.2893 20.2812L16.4567 15.4269C16.3454 14.7781 16.5605 14.1161 17.0319 13.6566L20.5587 10.2188L15.6848 9.51062C15.0333 9.41597 14.4702 9.00683 14.1789 8.41654L11.9992 4Z"></path></svg></span></span><span class="cdc-suspend-pill__item-number">0</span></button><button class="cdc-icon-btn cdc-suspend-pill__item cdc-icon-btn--text"><span class="cdc-svg-icon-con"><span class="cdc-svg-icon" style="width:24px;height:24px"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" xmlns="http://www.w3.org/2000/svg"><path d="M13.0001 4V6H17.5859L10.1787 13.4072L11.6043 14.81L19.0001 7.41424V12H21.0001V4H13.0001Z"></path><path d="M3 12.9996C3 8.71646 5.99202 5.13211 10 4.22266V6.28952C7.10851 7.15007 5 9.82862 5 12.9996C5 16.8656 8.13401 19.9996 12 19.9996C15.1709 19.9996 17.8494 17.8912 18.71 14.9999H20.7769C19.8674 19.0077 16.2831 21.9996 12 21.9996C7.02944 21.9996 3 17.9702 3 12.9996Z"></path></svg></span></span></button><button class="cdc-icon-btn cdc-suspend-pill__item cdc-icon-btn--text"><span class="cdc-svg-icon-con"><span class="cdc-svg-icon" style="width:24px;height:24px"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M2 6C2 4.34315 3.34315 3 5 3H17C18.6569 3 20 4.34315 20 6V11H18V6C18 5.44772 17.5523 5 17 5H5C4.44772 5 4 5.44772 4 6V18C4 18.5523 4.44772 19 5 19H12V21H5C3.34315 21 2 19.6569 2 18V6ZM6 8H12V10H6V8ZM6 12H15V14H6V12ZM22 16H19V13H17V16H14V18H17V21H19V18H22V16Z"></path></svg></span></span></button><div class="cdc-suspend-pill__line"></div><button class="cdc-icon-btn cdc-suspend-pill__item cdc-icon-btn--text"><span class="cdc-svg-icon-con"><span class="cdc-svg-icon" style="width:24px;height:24px"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" xmlns="http://www.w3.org/2000/svg"><path d="M16.5047 6H13V4H20V10.876H18V7.33313L14.4571 10.876L13.0429 9.46182L16.5047 6Z"></path><path d="M11 6.00006H7.4953L10.9571 9.46189L9.54291 10.8761L6 7.33319V10.8761H4V4.00006H11V6.00006Z"></path><path d="M7.4953 18.8761H11V20.8761H4V14.0001H6V17.543L9.54291 14.0001L10.9571 15.4143L7.4953 18.8761Z"></path><path d="M16.5047 18.8761H13V20.8761H20V14.0001H18V17.543L14.4571 14.0001L13.0429 15.4143L16.5047 18.8761Z"></path></svg></span></span></button><button class="cdc-icon-btn cdc-suspend-pill__item recommend cdc-icon-btn--text" track-click="{&quot;areaId&quot;:106019,&quot;recPolicyId&quot;:1002,&quot;elementId&quot;:2}" track-exposure="{&quot;areaId&quot;:106019,&quot;recPolicyId&quot;:1002,&quot;elementId&quot;:2}"><span class="cdc-svg-icon-con"><span class="cdc-svg-icon" style="width:24px;height:24px"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentcolor" xmlns="http://www.w3.org/2000/svg"><path d="M5 8H10V10H5V8Z"></path><path d="M10 12H5V14H10V12Z"></path><path d="M14 8H19V10H14V8Z"></path><path d="M19 12H14V14H19V12Z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M11 20.608L9.57047 20.1996C8.83303 19.9889 8.05701 19.9506 7.30243 20.0878L4.35777 20.6232C3.13009 20.8464 2 19.9033 2 18.6555V5.2669C2 4.2325 2.78877 3.36877 3.81893 3.27512L6.52892 3.02875C7.95704 2.89892 9.39058 3.21084 10.6356 3.9223L12 4.70194L13.3644 3.9223C14.6094 3.21084 16.043 2.89892 17.4711 3.02875L20.1811 3.27512C21.2112 3.36877 22 4.2325 22 5.2669V18.6555C22 19.9033 20.8699 20.8464 19.6422 20.6232L16.6976 20.0878C15.943 19.9506 15.167 19.9889 14.4295 20.1996L13 20.608L12.5 20.8535L12 20.8937L11.5 20.8535L11 20.608ZM6.70999 5.02054C7.73007 4.9278 8.75403 5.1506 9.64336 5.65879L11 6.43401V18.528L10.1199 18.2765C9.0875 17.9815 8.00107 17.928 6.94466 18.1201L4 18.6555V5.2669L6.70999 5.02054ZM13 18.528L13.8801 18.2765C14.9125 17.9815 15.9989 17.928 17.0553 18.1201L20 18.6555V5.2669L17.29 5.02054C16.2699 4.9278 15.246 5.1506 14.3566 5.65879L13 6.43401V18.528Z"></path></svg></span></span><span class="cdc-suspend-pill__item-text">推荐</span></button></div></div></div></div></div><script>
          if (!String.prototype.replaceAll) {
            String.prototype.replaceAll = function (str, newStr) {
              // If a regex pattern
              if (Object.prototype.toString.call(str).toLowerCase() === '[object regexp]') {
                return this.replace(str, newStr);
              }
        
              // If a string
              return this.replace(new RegExp(str, 'g'), newStr);
            };
          }
          </script><script src="https://developer.qcloudimg.com/static/jquery.min.js"></script><script src="https://cloud.tencent.com/qccomponent/login/api.js"></script><script src="https://cloudcache.tencent-cloud.com/qcloud/main/scripts/release/common/vendors/react/react.16.8.6.min.js"></script><script src="https://web.sdk.qcloud.com/player/tcplayer/release/v4.5.1/libs/TXLivePlayer-1.2.0.min.js" defer=""></script><script src="https://cloudcache.tencent-cloud.com/open/qcloud/video/tcplayer/libs/hls.min.0.13.2m.js"></script><script src="https://cloudcache.tencent-cloud.com/open/qcloud/video/tcplayer/tcplayer.v4.1.min.js"></script><script id="__NEXT_DATA__" type="application/json">{"props":{"isMobile":false,"isSupportWebp":false,"reqId":"mLMi6dwh83lCNxzIoDO9H","query":{"articleId":"1931716"},"platform":"other","env":"production","__N_SSP":true,"pageProps":{"fallback":{"#url:\"/api/article/detail\",params:#articleId:1931716,,":{"articleData":{"articleId":1931716,"codeLineNum":228,"readingTime":343,"wordsNum":1574},"articleInfo":{"articleId":1931716,"channel":2,"commentNum":0,"content":{"entityMap":{"0":{"type":"LINK","mutability":"MUTABLE","data":{"url":"https://yehe.woa.com/column/support-plan/article-edit/15455506"}},"1":{"type":"LINK","mutability":"MUTABLE","data":{"url":"https://yehe.woa.com/column/support-plan/article-edit/15455506"}},"2":{"type":"LINK","mutability":"MUTABLE","data":{"url":"https://yehe.woa.com/column/support-plan/article-edit/15455506"}},"3":{"type":"IMAGE","mutability":"IMMUTABLE","data":{"imageUrl":"https://ask.qcloudimg.com/http-save/yehe-1148605/b8e29490dd5410611165a36ff794480b.png","imageAlt":"1ab8c291255c43b1ee5712b3ba9f06ae.png","blockWidth":324,"blockHeight":28}},"4":{"type":"IMAGE","mutability":"IMMUTABLE","data":{"imageUrl":"https://ask.qcloudimg.com/http-save/yehe-1148605/84e726924e163874d6e869359867d5e7.png","imageAlt":"24812e49aac530ac066198a835fb583d.png","blockWidth":491,"blockHeight":242}},"5":{"type":"IMAGE","mutability":"IMMUTABLE","data":{"imageUrl":"https://ask.qcloudimg.com/http-save/yehe-1148605/29a988116d69d620eceff20414d5e37e.png","imageAlt":"7cdaf9ae9f1ee7f7285d6ec85e73ced7.png","blockWidth":423,"blockHeight":528}},"6":{"type":"IMAGE","mutability":"IMMUTABLE","data":{"imageUrl":"https://ask.qcloudimg.com/http-save/yehe-1148605/e0ceee28af65711d7bf7707ebda6f80d.png","imageAlt":"e2ac213790e9b6efb5f4bc938968fd0b.png","blockWidth":377,"blockHeight":298}},"7":{"type":"IMAGE","mutability":"IMMUTABLE","data":{"imageUrl":"https://ask.qcloudimg.com/http-save/yehe-1148605/277a6b5ccbb723001f3e989dcbe56337.png","imageAlt":"d9fb2ce11a26330d2f7f3496774c6768.png","blockWidth":223,"blockHeight":223}}},"blocks":[{"key":"a87fs","text":"大家好，我是红色石头！","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"dusm5","text":"在上三篇文章：","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"92ir1","text":"这可能是神经网络 LeNet-5 最详细的解释了！","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":25,"style":"ITALIC"}],"entityRanges":[{"offset":0,"length":25,"key":0}],"data":{}},{"key":"am1e1","text":"我用 PyTorch 复现了 LeNet-5 神经网络（MNIST 手写数据集篇）！","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":42,"style":"ITALIC"}],"entityRanges":[{"offset":0,"length":42,"key":1}],"data":{}},{"key":"bmcfl","text":"我用 PyTorch 复现了 LeNet-5 神经网络（CIFAR10 数据集篇）！","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":42,"style":"ITALIC"}],"entityRanges":[{"offset":0,"length":42,"key":2}],"data":{}},{"key":"5sco5","text":"详细介绍了卷积神经网络 LeNet-5 的理论部分和使用 PyTorch 复现 LeNet-5 网络来解决 MNIST 数据集和 CIFAR10 数据集。然而大多数实际应用中，我们需要自己构建数据集，进行识别。因此，本文将讲解一下如何使用 LeNet-5 训练自己的数据。","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"4bp9i","text":"正文开始！","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"98n13","text":"三、用 LeNet-5 训练自己的数据","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":19,"style":"BOLD"}],"entityRanges":[],"data":{}},{"key":"aks60","text":"下面使用 LeNet-5 网络来训练本地的数据并进行测试。数据集是本地的 LED 数字 0-9，尺寸为 28x28 单通道，跟 MNIST 数据集类似。训练集 0-9 各 95 张，测试集 0~9 各 40 张。图片样例如图所示：","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"bqrrr","text":"\ud83d","type":"atomic","depth":0,"inlineStyleRanges":[],"entityRanges":[{"offset":0,"length":1,"key":3}],"data":{}},{"key":"cnjl6","text":"3.1 数据预处理","type":"header-two","depth":0,"inlineStyleRanges":[{"offset":0,"length":9,"style":"BOLD"}],"entityRanges":[],"data":{"text":"3.1-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"}},{"key":"43qfi","text":"制作图片数据的索引","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":9,"style":"BOLD"}],"entityRanges":[],"data":{}},{"key":"9ui3k","text":"对于训练集和测试集，要分别制作对应的图片数据索引，即 train.txt 和 test.txt两个文件，每个 txt 中包含每个图片的目录和对应类别 class。示意图如下：","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"ash1e","text":"\ud83d","type":"atomic","depth":0,"inlineStyleRanges":[],"entityRanges":[{"offset":0,"length":1,"key":4}],"data":{}},{"key":"bsvq3","text":"制作图片数据索引的 python 脚本程序如下：","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"8f4pl","text":"import os\n\n\ntrain_txt_path = os.path.join(\"data\", \"LEDNUM\", \"train.txt\")\ntrain_dir = os.path.join(\"data\", \"LEDNUM\", \"train_data\")\nvalid_txt_path = os.path.join(\"data\", \"LEDNUM\", \"test.txt\")\nvalid_dir = os.path.join(\"data\", \"LEDNUM\", \"test_data\")\n\n\ndef gen_txt(txt_path, img_dir):\n    f = open(txt_path, 'w')\n\n\n    for root, s_dirs, _ in os.walk(img_dir, topdown=True):  # 获取 train文件下各文件夹名称\n        for sub_dir in s_dirs:\n            i_dir = os.path.join(root, sub_dir)             # 获取各类的文件夹 绝对路径\n            img_list = os.listdir(i_dir)                    # 获取类别文件夹下所有png图片的路径\n            for i in range(len(img_list)):\n                if not img_list[i].endswith('jpg'):         # 若不是png文件，跳过\n                    continue\n                label = img_list[i].split('_')[0]\n                img_path = os.path.join(i_dir, img_list[i])\n                line = img_path + ' ' + label + '\\n'\n                f.write(line)\n    f.close()\n\n\nif __name__ == '__main__':\n    gen_txt(train_txt_path, train_dir)\n    gen_txt(valid_txt_path, valid_dir)","type":"code-block","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{"syntax":"javascript"}},{"key":"c3acv","text":"运行脚本之后就在 ./data/LEDNUM/ 目录下生成 train.txt 和 test.txt 两个索引文件。","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"7r0pj","text":"构建Dataset子类","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":11,"style":"BOLD"}],"entityRanges":[],"data":{}},{"key":"3f6qp","text":"pytorch 加载自己的数据集，需要写一个继承自 torch.utils.data 中 Dataset 类，并修改其中的 __init__ 方法、__getitem__ 方法、__len__ 方法。默认加载的都是图片，__init__ 的目的是得到一个包含数据和标签的 list，每个元素能找到图片位置和其对应标签。然后用 __getitem__ 方法得到每个元素的图像像素矩阵和标签，返回 img 和 label。","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"45aum","text":"from PIL import Image\nfrom torch.utils.data import Dataset\n\n\nclass MyDataset(Dataset):\n    def __init__(self, txt_path, transform = None, target_transform = None):\n        fh = open(txt_path, 'r')\n        imgs = []\n        for line in fh:\n            line = line.rstrip()\n            words = line.split()\n            imgs.append((words[0], int(words[1])))\n            self.imgs = imgs \n            self.transform = transform\n            self.target_transform = target_transform\n    def __getitem__(self, index):\n        fn, label = self.imgs[index]\n        #img = Image.open(fn).convert('RGB') \n        img = Image.open(fn)\n        if self.transform is not None:\n            img = self.transform(img) \n        return img, label\n    def __len__(self):\n        return len(self.imgs)","type":"code-block","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{"syntax":"javascript"}},{"key":"5nrhh","text":"getitem 是核心函数。self.imgs 是一个 list，self.imgs[index] 是一个 str，包含图片路径，图片标签，这些信息是从上面生成的txt文件中读取；利用 Image.open 对图片进行读取，注意这里的 img 是单通道还是三通道的；self.transform(img) 对图片进行处理，这个 transform 里边可以实现减均值、除标准差、随机裁剪、旋转、翻转、放射变换等操作。","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"707j3","text":"当 Mydataset构 建好，剩下的操作就交给 DataLoder，在 DataLoder 中，会触发 Mydataset 中的 getiterm 函数读取一张图片的数据和标签，并拼接成一个 batch 返回，作为模型真正的输入。","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"etvvo","text":"pipline_train = transforms.Compose([\n    #随机旋转图片\n    transforms.RandomHorizontalFlip(),\n    #将图片尺寸resize到32x32\n    transforms.Resize((32,32)),\n    #将图片转化为Tensor格式\n    transforms.ToTensor(),\n    #正则化(当模型出现过拟合的情况时，用来降低模型的复杂度)\n    transforms.Normalize((0.1307,),(0.3081,))    \n])\npipline_test = transforms.Compose([\n    #将图片尺寸resize到32x32\n    transforms.Resize((32,32)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,),(0.3081,))\n])\ntrain_data = MyDataset('./data/LEDNUM/train.txt', transform=pipline_train)\ntest_data = MyDataset('./data/LEDNUM/test.txt', transform=pipline_test)\n\n\n#train_data 和test_data包含多有的训练与测试数据，调用DataLoader批量加载\ntrainloader = torch.utils.data.DataLoader(dataset=train_data, batch_size=8, shuffle=True)\ntestloader = torch.utils.data.DataLoader(dataset=test_data, batch_size=4, shuffle=False)","type":"code-block","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{"syntax":"javascript"}},{"key":"4l8uh","text":"3.2 搭建 LeNet-5 神经网络结构","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":21,"style":"BOLD"}],"entityRanges":[],"data":{}},{"key":"43rt1","text":"class LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5) \n        self.relu = nn.ReLU()\n        self.maxpool1 = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.maxpool2 = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(16*5*5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool1(x)\n        x = self.conv2(x)\n        x = self.maxpool2(x)\n        x = x.view(-1, 16*5*5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        output = F.log_softmax(x, dim=1)\n        return output","type":"code-block","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{"syntax":"javascript"}},{"key":"66pjm","text":"3.3 将定义好的网络结构搭载到 GPU/CPU，并定义优化器","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":31,"style":"BOLD"}],"entityRanges":[],"data":{}},{"key":"68v7","text":"#创建模型，部署gpu\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = LeNet().to(device)\n#定义优化器\noptimizer = optim.Adam(model.parameters(), lr=0.001)","type":"code-block","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{"syntax":"javascript"}},{"key":"2bcnq","text":"3.4 定义训练函数","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":10,"style":"BOLD"}],"entityRanges":[],"data":{}},{"key":"1j26o","text":"def train_runner(model, device, trainloader, optimizer, epoch):\n    #训练模型, 启用 BatchNormalization 和 Dropout, 将BatchNormalization和Dropout置为True\n    model.train()\n    total = 0\n    correct =0.0\n\n\n    #enumerate迭代已加载的数据集,同时获取数据和数据下标\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n        #把模型部署到device上\n        inputs, labels = inputs.to(device), labels.to(device)\n        #初始化梯度\n        optimizer.zero_grad()\n        #保存训练结果\n        outputs = model(inputs)\n        #计算损失和\n        #多分类情况通常使用cross_entropy(交叉熵损失函数), 而对于二分类问题, 通常使用sigmod\n        loss = F.cross_entropy(outputs, labels)\n        #获取最大概率的预测结果\n        #dim=1表示返回每一行的最大值对应的列下标\n        predict = outputs.argmax(dim=1)\n        total += labels.size(0)\n        correct += (predict == labels).sum().item()\n        #反向传播\n        loss.backward()\n        #更新参数\n        optimizer.step()\n        if i % 100 == 0:\n            #loss.item()表示当前loss的数值\n            print(\"Train Epoch{} \\t Loss: {:.6f}, accuracy: {:.6f}%\".format(epoch, loss.item(), 100*(correct/total)))\n            Loss.append(loss.item())\n            Accuracy.append(correct/total)\n    return loss.item(), correct/total","type":"code-block","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{"syntax":"javascript"}},{"key":"7mu2h","text":"3.5 定义测试函数","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":10,"style":"BOLD"}],"entityRanges":[],"data":{}},{"key":"f2m4p","text":"def test_runner(model, device, testloader):\n    #模型验证, 必须要写, 否则只要有输入数据, 即使不训练, 它也会改变权值\n    #因为调用eval()将不启用 BatchNormalization 和 Dropout, BatchNormalization和Dropout置为False\n    model.eval()\n    #统计模型正确率, 设置初始值\n    correct = 0.0\n    test_loss = 0.0\n    total = 0\n    #torch.no_grad将不会计算梯度, 也不会进行反向传播\n    with torch.no_grad():\n        for data, label in testloader:\n            data, label = data.to(device), label.to(device)\n            output = model(data)\n            test_loss += F.cross_entropy(output, label).item()\n            predict = output.argmax(dim=1)\n            #计算正确数量\n            total += label.size(0)\n            correct += (predict == label).sum().item()\n        #计算损失值\n        print(\"test_avarage_loss: {:.6f}, accuracy: {:.6f}%\".format(test_loss/total, 100*(correct/total)))","type":"code-block","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{"syntax":"javascript"}},{"key":"at025","text":"3.6 运行","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":6,"style":"BOLD"}],"entityRanges":[],"data":{}},{"key":"e5b0b","text":"#调用\nepoch = 5\nLoss = []\nAccuracy = []\nfor epoch in range(1, epoch+1):\n    print(\"start_time\",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())))\n    loss, acc = train_runner(model, device, trainloader, optimizer, epoch)\n    Loss.append(loss)\n    Accuracy.append(acc)\n    test_runner(model, device, testloader)\n    print(\"end_time: \",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),'\\n')\n\n\nprint('Finished Training')\nplt.subplot(2,1,1)\nplt.plot(Loss)\nplt.title('Loss')\nplt.show()\nplt.subplot(2,1,2)\nplt.plot(Accuracy)\nplt.title('Accuracy')\nplt.show()","type":"code-block","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{"syntax":"javascript"}},{"key":"4ev3","text":"\ud83d","type":"atomic","depth":0,"inlineStyleRanges":[],"entityRanges":[{"offset":0,"length":1,"key":5}],"data":{}},{"key":"cfr8f","text":"经历 5 次 epoch 的 loss 和 accuracy 曲线如下：","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"6vj7k","text":"\ud83d","type":"atomic","depth":0,"inlineStyleRanges":[],"entityRanges":[{"offset":0,"length":1,"key":6}],"data":{}},{"key":"32j0d","text":"3.7 模型保存","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":8,"style":"BOLD"}],"entityRanges":[],"data":{}},{"key":"d6bf3","text":"torch.save(model, './models/model-mine.pth') #保存模型","type":"code-block","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{"syntax":"javascript"}},{"key":"5hjhh","text":"3.8 模型测试","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":8,"style":"BOLD"}],"entityRanges":[],"data":{}},{"key":"4va0g","text":"下面使用上面训练的模型对一张 LED 图片进行测试。","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"193dp","text":"from PIL import Image\nimport numpy as np\n\n\nif __name__ == '__main__':\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = torch.load('./models/model-mine.pth') #加载模型\n    model = model.to(device)\n    model.eval()    #把模型转为test模式\n\n\n    #读取要预测的图片\n    # 读取要预测的图片\n    img = Image.open(\"./images/test_led.jpg\") # 读取图像\n    #img.show()\n    plt.imshow(img,cmap=\"gray\") # 显示图片\n    plt.axis('off') # 不显示坐标轴\n    plt.show()\n\n\n    # 导入图片，图片扩展后为[1，1，32，32]\n    trans = transforms.Compose(\n        [\n            #将图片尺寸resize到32x32\n            transforms.Resize((32,32)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.1307,), (0.3081,))\n        ])\n    img = trans(img)\n    img = img.to(device)\n    img = img.unsqueeze(0)  #图片扩展多一维,因为输入到保存的模型中是4维的[batch_size,通道,长，宽]，而普通图片只有三维，[通道,长，宽]\n\n\n    # 预测 \n    output = model(img)\n    prob = F.softmax(output,dim=1) #prob是10个分类的概率\n    print(\"概率：\",prob)\n    value, predicted = torch.max(output.data, 1)\n    predict = output.argmax(dim=1)\n    print(\"预测类别：\",predict.item())","type":"code-block","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{"syntax":"javascript"}},{"key":"5l3dn","text":"\ud83d","type":"atomic","depth":0,"inlineStyleRanges":[],"entityRanges":[{"offset":0,"length":1,"key":7}],"data":{}},{"key":"1j1kc","text":"概率：tensor([[7.2506e-11, 7.0065e-18, 7.1749e-06, 7.4855e-13, 7.3532e-08, 8.5405e-17,\n         2.5753e-15, 9.7887e-10, 2.7855e-05, 9.9996e-01]],\n       grad_fn=\u003cSoftmaxBackward\u003e)\n预测类别：9","type":"code-block","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{"syntax":"javascript"}},{"key":"djrs8","text":"模型预测结果正确！","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"1oe6a","text":"以上就是 PyTorch 构建 LeNet-5 卷积神经网络并用它来识别自定义数据集的例子。全文的代码都是可以顺利运行的，建议大家自己跑一边。","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"72km6","text":"总结：","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":3,"style":"BOLD"}],"entityRanges":[],"data":{}},{"key":"4hb31","text":"是我们目前分别复现了 LeNet-5 来识别 MNIST、CIFAR10 和自定义数据集，基本上涵盖了基于 PyToch 的 LeNet-5 实战的所有内容。希望对大家有所帮助！","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"6nb8t","text":"所有完整的代码我都放在 GitHub 上，GitHub地址为：","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"bit13","text":"https://github.com/RedstoneWill/ObjectDetectionLearner/tree/main/LeNet-5","type":"unstyled","depth":0,"inlineStyleRanges":[{"offset":0,"length":72,"style":"ITALIC"}],"entityRanges":[],"data":{}}]},"createTime":1641796528,"ext":{"closeTextLink":0,"comment_ban":0,"description":"","focusRead":0},"favNum":0,"isOriginal":0,"likeNum":1,"pic":"https://ask.qcloudimg.com/http-save/yehe-1148605/b8e29490dd5410611165a36ff794480b.png","plain":"大家好，我是红色石头！\n在上三篇文章：\n这可能是神经网络 LeNet-5 最详细的解释了！\n我用 PyTorch 复现了 LeNet-5 神经网络（MNIST 手写数据集篇）！\n我用 PyTorch 复现了 LeNet-5 神经网络（CIFAR10 数据集篇）！\n详细介绍了卷积神经网络 LeNet-5 的理论部分和使用 PyTorch 复现 LeNet-5 网络来解决 MNIST 数据集和 CIFAR10 数据集。然而大多数实际应用中，我们需要自己构建数据集，进行识别。因此，本文将讲解一下如何使用 LeNet-5 训练自己的数据。\n正文开始！\n三、用 LeNet-5 训练自己的数据\n下面使用 LeNet-5 网络来训练本地的数据并进行测试。数据集是本地的 LED 数字 0-9，尺寸为 28x28 单通道，跟 MNIST 数据集类似。训练集 0-9 各 95 张，测试集 0~9 各 40 张。图片样例如图所示：\n📷\n3.1 数据预处理\n制作图片数据的索引\n对于训练集和测试集，要分别制作对应的图片数据索引，即 train.txt 和 test.txt两个文件，每个 txt 中包含每个图片的目录和对应类别 class。示意图如下：\n📷\n制作图片数据索引的 python 脚本程序如下：\nimport os\n\n\ntrain_txt_path = os.path.join(\"data\", \"LEDNUM\", \"train.txt\")\ntrain_dir = os.path.join(\"data\", \"LEDNUM\", \"train_data\")\nvalid_txt_path = os.path.join(\"data\", \"LEDNUM\", \"test.txt\")\nvalid_dir = os.path.join(\"data\", \"LEDNUM\", \"test_data\")\n\n\ndef gen_txt(txt_path, img_dir):\n    f = open(txt_path, 'w')\n\n\n    for root, s_dirs, _ in os.walk(img_dir, topdown=True):  # 获取 train文件下各文件夹名称\n        for sub_dir in s_dirs:\n            i_dir = os.path.join(root, sub_dir)             # 获取各类的文件夹 绝对路径\n            img_list = os.listdir(i_dir)                    # 获取类别文件夹下所有png图片的路径\n            for i in range(len(img_list)):\n                if not img_list[i].endswith('jpg'):         # 若不是png文件，跳过\n                    continue\n                label = img_list[i].split('_')[0]\n                img_path = os.path.join(i_dir, img_list[i])\n                line = img_path + ' ' + label + '\\n'\n                f.write(line)\n    f.close()\n\n\nif __name__ == '__main__':\n    gen_txt(train_txt_path, train_dir)\n    gen_txt(valid_txt_path, valid_dir)\n运行脚本之后就在 ./data/LEDNUM/ 目录下生成 train.txt 和 test.txt 两个索引文件。\n构建Dataset子类\npytorch 加载自己的数据集，需要写一个继承自 torch.utils.data 中 Dataset 类，并修改其中的 __init__ 方法、__getitem__ 方法、__len__ 方法。默认加载的都是图片，__init__ 的目的是得到一个包含数据和标签的 list，每个元素能找到图片位置和其对应标签。然后用 __getitem__ 方法得到每个元素的图像像素矩阵和标签，返回 img 和 label。\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\n\nclass MyDataset(Dataset):\n    def __init__(self, txt_path, transform = None, target_transform = None):\n        fh = open(txt_path, 'r')\n        imgs = []\n        for line in fh:\n            line = line.rstrip()\n            words = line.split()\n            imgs.append((words[0], int(words[1])))\n            self.imgs = imgs \n            self.transform = transform\n            self.target_transform = target_transform\n    def __getitem__(self, index):\n        fn, label = self.imgs[index]\n        #img = Image.open(fn).convert('RGB') \n        img = Image.open(fn)\n        if self.transform is not None:\n            img = self.transform(img) \n        return img, label\n    def __len__(self):\n        return len(self.imgs)\ngetitem 是核心函数。self.imgs 是一个 list，self.imgs[index] 是一个 str，包含图片路径，图片标签，这些信息是从上面生成的txt文件中读取；利用 Image.open 对图片进行读取，注意这里的 img 是单通道还是三通道的；self.transform(img) 对图片进行处理，这个 transform 里边可以实现减均值、除标准差、随机裁剪、旋转、翻转、放射变换等操作。\n当 Mydataset构 建好，剩下的操作就交给 DataLoder，在 DataLoder 中，会触发 Mydataset 中的 getiterm 函数读取一张图片的数据和标签，并拼接成一个 batch 返回，作为模型真正的输入。\npipline_train = transforms.Compose([\n    #随机旋转图片\n    transforms.RandomHorizontalFlip(),\n    #将图片尺寸resize到32x32\n    transforms.Resize((32,32)),\n    #将图片转化为Tensor格式\n    transforms.ToTensor(),\n    #正则化(当模型出现过拟合的情况时，用来降低模型的复杂度)\n    transforms.Normalize((0.1307,),(0.3081,))    \n])\npipline_test = transforms.Compose([\n    #将图片尺寸resize到32x32\n    transforms.Resize((32,32)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,),(0.3081,))\n])\ntrain_data = MyDataset('./data/LEDNUM/train.txt', transform=pipline_train)\ntest_data = MyDataset('./data/LEDNUM/test.txt', transform=pipline_test)\n\n\n#train_data 和test_data包含多有的训练与测试数据，调用DataLoader批量加载\ntrainloader = torch.utils.data.DataLoader(dataset=train_data, batch_size=8, shuffle=True)\ntestloader = torch.utils.data.DataLoader(dataset=test_data, batch_size=4, shuffle=False)\n3.2 搭建 LeNet-5 神经网络结构\nclass LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5) \n        self.relu = nn.ReLU()\n        self.maxpool1 = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.maxpool2 = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(16*5*5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool1(x)\n        x = self.conv2(x)\n        x = self.maxpool2(x)\n        x = x.view(-1, 16*5*5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n3.3 将定义好的网络结构搭载到 GPU/CPU，并定义优化器\n#创建模型，部署gpu\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = LeNet().to(device)\n#定义优化器\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n3.4 定义训练函数\ndef train_runner(model, device, trainloader, optimizer, epoch):\n    #训练模型, 启用 BatchNormalization 和 Dropout, 将BatchNormalization和Dropout置为True\n    model.train()\n    total = 0\n    correct =0.0\n\n\n    #enumerate迭代已加载的数据集,同时获取数据和数据下标\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n        #把模型部署到device上\n        inputs, labels = inputs.to(device), labels.to(device)\n        #初始化梯度\n        optimizer.zero_grad()\n        #保存训练结果\n        outputs = model(inputs)\n        #计算损失和\n        #多分类情况通常使用cross_entropy(交叉熵损失函数), 而对于二分类问题, 通常使用sigmod\n        loss = F.cross_entropy(outputs, labels)\n        #获取最大概率的预测结果\n        #dim=1表示返回每一行的最大值对应的列下标\n        predict = outputs.argmax(dim=1)\n        total += labels.size(0)\n        correct += (predict == labels).sum().item()\n        #反向传播\n        loss.backward()\n        #更新参数\n        optimizer.step()\n        if i % 100 == 0:\n            #loss.item()表示当前loss的数值\n            print(\"Train Epoch{} \\t Loss: {:.6f}, accuracy: {:.6f}%\".format(epoch, loss.item(), 100*(correct/total)))\n            Loss.append(loss.item())\n            Accuracy.append(correct/total)\n    return loss.item(), correct/total\n3.5 定义测试函数\ndef test_runner(model, device, testloader):\n    #模型验证, 必须要写, 否则只要有输入数据, 即使不训练, 它也会改变权值\n    #因为调用eval()将不启用 BatchNormalization 和 Dropout, BatchNormalization和Dropout置为False\n    model.eval()\n    #统计模型正确率, 设置初始值\n    correct = 0.0\n    test_loss = 0.0\n    total = 0\n    #torch.no_grad将不会计算梯度, 也不会进行反向传播\n    with torch.no_grad():\n        for data, label in testloader:\n            data, label = data.to(device), label.to(device)\n            output = model(data)\n            test_loss += F.cross_entropy(output, label).item()\n            predict = output.argmax(dim=1)\n            #计算正确数量\n            total += label.size(0)\n            correct += (predict == label).sum().item()\n        #计算损失值\n        print(\"test_avarage_loss: {:.6f}, accuracy: {:.6f}%\".format(test_loss/total, 100*(correct/total)))\n3.6 运行\n#调用\nepoch = 5\nLoss = []\nAccuracy = []\nfor epoch in range(1, epoch+1):\n    print(\"start_time\",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())))\n    loss, acc = train_runner(model, device, trainloader, optimizer, epoch)\n    Loss.append(loss)\n    Accuracy.append(acc)\n    test_runner(model, device, testloader)\n    print(\"end_time: \",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),'\\n')\n\n\nprint('Finished Training')\nplt.subplot(2,1,1)\nplt.plot(Loss)\nplt.title('Loss')\nplt.show()\nplt.subplot(2,1,2)\nplt.plot(Accuracy)\nplt.title('Accuracy')\nplt.show()\n📷\n经历 5 次 epoch 的 loss 和 accuracy 曲线如下：\n📷\n3.7 模型保存\ntorch.save(model, './models/model-mine.pth') #保存模型\n3.8 模型测试\n下面使用上面训练的模型对一张 LED 图片进行测试。\nfrom PIL import Image\nimport numpy as np\n\n\nif __name__ == '__main__':\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = torch.load('./models/model-mine.pth') #加载模型\n    model = model.to(device)\n    model.eval()    #把模型转为test模式\n\n\n    #读取要预测的图片\n    # 读取要预测的图片\n    img = Image.open(\"./images/test_led.jpg\") # 读取图像\n    #img.show()\n    plt.imshow(img,cmap=\"gray\") # 显示图片\n    plt.axis('off') # 不显示坐标轴\n    plt.show()\n\n\n    # 导入图片，图片扩展后为[1，1，32，32]\n    trans = transforms.Compose(\n        [\n            #将图片尺寸resize到32x32\n            transforms.Resize((32,32)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.1307,), (0.3081,))\n        ])\n    img = trans(img)\n    img = img.to(device)\n    img = img.unsqueeze(0)  #图片扩展多一维,因为输入到保存的模型中是4维的[batch_size,通道,长，宽]，而普通图片只有三维，[通道,长，宽]\n\n\n    # 预测 \n    output = model(img)\n    prob = F.softmax(output,dim=1) #prob是10个分类的概率\n    print(\"概率：\",prob)\n    value, predicted = torch.max(output.data, 1)\n    predict = output.argmax(dim=1)\n    print(\"预测类别：\",predict.item())\n📷\n概率：tensor([[7.2506e-11, 7.0065e-18, 7.1749e-06, 7.4855e-13, 7.3532e-08, 8.5405e-17,\n         2.5753e-15, 9.7887e-10, 2.7855e-05, 9.9996e-01]],\n       grad_fn=\u003cSoftmaxBackward\u003e)\n预测类别：9\n模型预测结果正确！\n以上就是 PyTorch 构建 LeNet-5 卷积神经网络并用它来识别自定义数据集的例子。全文的代码都是可以顺利运行的，建议大家自己跑一边。\n总结：\n是我们目前分别复现了 LeNet-5 来识别 MNIST、CIFAR10 和自定义数据集，基本上涵盖了基于 PyToch 的 LeNet-5 实战的所有内容。希望对大家有所帮助！\n所有完整的代码我都放在 GitHub 上，GitHub地址为：\nhttps://github.com/RedstoneWill/ObjectDetectionLearner/tree/main/LeNet-5","showReadNum":1344,"sourceDetail":null,"sourceType":99,"status":2,"summary":"我用 PyTorch 复现了 LeNet-5 神经网络（MNIST 手写数据集篇）！","tagIds":[10735,10332,10690,10497,10284],"title":"我用 PyTorch 复现了 LeNet-5 神经网络（自定义数据集篇）！","uid":1148605,"updateTime":1641796528,"userSummary":"","userUpdateTime":1641796528},"authorInfo":{"articleNum":0,"avatarUrl":"https://ask.qcloudimg.com/avatar/1148605/0awbobj21j.jpg","company":"","introduce":"因为笨鸟，所以先飞","isProfessionVerified":0,"nickname":"红色石头","privilege":1,"title":"","uid":1148605},"authorType":{"isBlogMoveAuthor":1,"isCoCreator":0,"isInternalAuthor":0,"isOriginalAuthor":0},"classify":[{"id":2,"name":"人工智能"}],"columnInfo":{"columnAvatar":"https://imgcache.qq.com/qcloud/developer/images/release/column-icons/14.png","columnDesc":"","columnId":1637,"columnName":"红色石头的机器学习之路","createTime":1512976334,"createUid":1148605,"memberNum":1,"showArticleNum":239,"showConcernNum":54},"columnList":[{"columnAvatar":"https://imgcache.qq.com/qcloud/developer/images/release/column-icons/14.png","columnDesc":"","columnId":1637,"columnName":"红色石头的机器学习之路","createTime":1512976334,"createUid":1148605,"memberNum":1,"showArticleNum":239,"showConcernNum":54}],"editTime":0,"isTencent":false,"longtailTags":[],"publishTime":1641796528,"sourceDetail":{"blogType":2,"blogUrl":"http://blog.csdn.net/red_stone1?viewmode=contents","channelSource":"csdn","originalTime":"2022/01/04 17:29:00","sourceAuthor":"","sourceLink":"https://redstonewill.blog.csdn.net/article/details/122314811","wechatNickName":"","wechatUserName":""},"tags":[{"categoryId":3,"createTime":"2018-09-06T18:31:34+08:00","groupId":10128,"groupName":"人工智能技术","tagId":10735,"tagName":"pytorch"},{"categoryId":3,"createTime":"2018-05-15T10:41:12+08:00","groupId":10128,"groupName":"人工智能技术","tagId":10332,"tagName":"神经网络"},{"categoryId":3,"createTime":"2018-09-06T18:31:32+08:00","groupId":10128,"groupName":"人工智能技术","tagId":10690,"tagName":"卷积神经网络"},{"categoryId":2,"createTime":"2018-05-28T17:13:27+08:00","groupId":0,"groupName":"","tagId":10497,"tagName":"腾讯云测试服务"},{"categoryId":3,"createTime":"2018-05-11T12:34:02+08:00","groupId":10133,"groupName":"开发技术","tagId":10284,"tagName":"github"}],"textLink":[{"ext":{"categoryId":1019,"categoryName":"通用技术 - 人工智能","desc":"卷积神经网络（Convolutional Neural Network, CNN）是一种深度学习模型，通常用于图像、视频、语音等信号数据的分类和识别任务。","kpCount":7,"name":"卷积神经网络","pCategoryId":1002,"termId":1640},"id":3372,"link":"https://cloud.tencent.com/developer/techpedia/1640","sources":[2],"text":"卷积神经网络"},{"ext":{"categoryId":1021,"categoryName":"通用技术 - 大数据","desc":"数据预处理是指在进行数据分析和建模前，对原始数据进行清洗、转换、集成、规范化等一系列处理过程。数据预处理旨在减少数据分析和建模过程中的错误和偏差，提高数据的质量和可靠性。","kpCount":6,"name":"数据预处理","pCategoryId":1002,"termId":1719},"id":3440,"link":"https://cloud.tencent.com/developer/techpedia/1719","sources":[2],"text":"数据预处理"},{"ext":null,"id":617,"link":"https://cloud.tencent.com/product/crg","sources":[1],"text":"图片标签"},{"ext":{"categoryId":1021,"categoryName":"通用技术 - 大数据","desc":"数据索引是一种用于加快数据检索速度的数据结构，它可以按照特定的规则和算法将数据组织成一种特定的数据结构，使得检索数据时可以快速定位到所需的数据。数据索引通常是在数据库或搜索引擎等大型数据存储系统中使用的。","kpCount":7,"name":"数据索引","pCategoryId":1002,"termId":1730},"id":3447,"link":"https://cloud.tencent.com/developer/techpedia/1730","sources":[2],"text":"数据索引"},{"ext":{"categoryId":1025,"categoryName":"通用技术 - 运维","desc":"GitHub是一个基于web的版本控制和协作平台，主要用于存储、管理和分享开源代码和项目。它提供了基于git的版本控制功能，使得多个开发者可以在同一个代码库中协同开发，并且能够轻松地跟踪代码的变化。同时，GitHub还提供了许多其他功能，如问题跟踪、代码审查、代码片段分享、自动化测试等等，使得开发者可以更加高效地进行开发和协作。","kpCount":11,"name":"GitHub","pCategoryId":1002,"termId":1872},"id":3579,"link":"https://cloud.tencent.com/developer/techpedia/1872","sources":[2],"text":"GitHub"},{"ext":null,"id":5,"link":"https://cloud.tencent.com/act/pro/promotion-cvm","sources":[1],"text":"GPU"}]},"#url:\"/api/tag/products\",params:#tagIds:@10735,10332,10690,10497,10284,,objectType:1,objectId:1931716,,":[{"adActivity":{"id":5738,"lightSpotLabel":"HOT","pageUrl":"https://cloud.tencent.com/act/pro/Featured","priority":1,"startTime":"2023/12/12 17:58:46","title":"精选特惠 用云无忧"},"cnName":"内容识别","desc":"内容识别（Content Recognition，CR）是腾讯云数据万象推出的对图片内容进行识别、理解的服务，集成腾讯云 AI 的多种强大功能，对存储在腾讯云对象存储 COS 的数据提供图片标签、图片修复、二维码识别、语音识别、质量评估等增值服务。","docURL":"https://cloud.tencent.com/document/product/1239","hasActivity":false,"icon":"https://main.qcloudimg.com/image/product/2524/32_32/blue.svg","introURL":"https://cloud.tencent.com/product/crg","name":"crg","productId":11015,"shortDesc":"集成腾讯云 AI 的强大功能，为客户提供图片内容识别和理解能力","tagId":11108}],"#url:\"/api/common/runnable-codes\",params:#objectId:1931716,,":[]},"tdk":{"title":"我用 PyTorch 复现了 LeNet-5 神经网络（自定义数据集篇）！-腾讯云开发者社区-腾讯云","keywords":"pytorch,神经网络,卷积神经网络,腾讯云测试服务,github","description":"我用 PyTorch 复现了 LeNet-5 神经网络（MNIST 手写数据集篇）！"},"meta":{"subject":"通用技术-人工智能技术-pytorch,通用技术-人工智能技术-神经网络,通用技术-人工智能技术-卷积神经网络,平台服务-空类-腾讯云测试服务,通用技术-开发技术-github","subjectTime":"2022-01-10 14:35:28","articleSource":"B","magicSource":"N","authorType":"Z","productSlug":"crg"},"link":{"canonical":"https://cloud.tencent.com/developer/article/1931716"},"cssName":["Article","DraftMaster","Player"],"session":{"isLogined":false,"isQCloudLogined":false,"isQCommunityLogined":false,"isDifferentUin":false},"pvId":"mLMi6dwh83lCNxzIoDO9H","clientIp":"182.113.29.210"}},"page":"/article/[articleId]","query":{"articleId":"1931716"},"buildId":"TBn4s1UqVQWVFb5OkG95R","assetPrefix":"https://qccommunity.qcloudimg.com/community","isFallback":false,"gssp":true,"appGip":true,"scriptLoader":[]}</script></body></html>